
Gabriel Staples

This file is part of eRCaGuy_dotfiles: https://github.com/ElectricRCAircraftGuy/eRCaGuy_dotfiles

"I understand crossing your fingers is a form of debugging. If it doesn't pass, cross your fingers and try again."
    - said nobody ever
    (by Gabriel Staples, 25 June 2020)

"You are making progress if each mistake is a new one."
    - One of the many random quotes displayed on the Eclipse IDE startup splash screen when the "Darkest Dark Theme with DevStyle 2002.5.5" plugin is installed

Me: "I am a documentation expert." Boss: "What about diagramming?" Me: "Oh...(foot in mouth)." [I'm great at documentation, just not drawing diagrams to demonstrate designs.]
New assertion: Me: "I am a foot-in-mouth expert." Boss: "Yep."
That should be a comic.


====================================================================================================
= Doxygen: = 
====================================================================================================

See other examples here:
1. http://www.doxygen.nl/manual/commands.html
1. https://stackoverflow.com/questions/15398711/whats-the-right-way-to-reference-a-parameter-in-doxygen/56745246#56745246
1. https://stackoverflow.com/questions/34196663/stm32-how-to-get-last-reset-status/54728664#54728664
1. https://stackoverflow.com/questions/385975/error-handling-in-c-code/59221452#59221452

Here's a bunch of Doxygen examples for easy copy/pasting into your code when you are frequently writing Doxygen:

Full Doxygen function header example:

    /// \brief          A brief one or two line description of the function.
    /// \note           An important note the user should be aware of--perhaps many lines.
    /// \details        Extra details.
    ///                 Perhaps
    ///                 even
    ///                 a long
    ///                 paragraph.
    /// \param[in]      var1            Description of variable one, an input
    /// \param[in]      my_longer_var2  Description of variable two, an input
    /// \param[out]     var3            Description of variable three, an output (usu. via a pointer
    ///                                 to a variable)
    /// \param[in,out]  var4            Description of variable four, an input/output (usu. via a
    ///                                 pointer) since its initial value is read and used, but then 
    ///                                 it is also updated by the function at some point
    /// \return         Description of return types. It may be an enum, with these
    ///                 possible values:
    ///                 - #ENUM_VALUE_1
    ///                 - #ENUM_VALUE_2
    ///                 - #ENUM_VALUE_3
    my_enum_t myFunc(int var1, int var2, int* var3, int* var4)
    {
        // function implementation here
        
        my_enum_t error = ENUM_VALUE_1;
        
        // Check for NULL pointers
        if (!var3 || !var4)
        {
            // var3 or var4 are NULL pointers, which means they can't be dereferenced
            error = ENUM_VALUE_2;
            goto done;
        }

        if (something_else)
        {
            error = ENUM_VALUE_3;
            goto done;
        }

    done:
        return error;
    }

You may also use `@` instead of `\`:

    /// @brief          A brief one or two line description of the function.
    /// @param[in]      var1            Description of variable one, an input
    /// @param[in]      my_longer_var2  Description of variable two, an input
    /// @param[out]     var3            Description of variable three, an output (usu. via a pointer
    ///                                 to a variable)
    /// @param[in,out]  var4            Description of variable four, an input/output (usu. via a
    ///                                 pointer) since its initial value is read and used, but then 
    ///                                 it is also updated by the function at some point
    /// @return         None
    void myFunc(int var1, int var2, int* var3, int* var4)
    {
        // function implementation here
    }

And here's this shorter version again now with `\` again instead of `@`:

    /// \brief          A brief one or two line description of the function.
    /// \param[in]      var1            Description of variable one, an input
    /// \param[in]      my_longer_var2  Description of variable two, an input
    /// \param[out]     var3            Description of variable three, an output (usu. via a pointer
    ///                                 to a variable)
    /// \param[in,out]  var4            Description of variable four, an input/output (usu. via a
    ///                                 pointer) since its initial value is read and used, but then 
    ///                                 it is also updated by the function at some point
    /// \return         None
    void myFunc(int var1, int var2, int* var3, int* var4)
    {
        // function implementation here
    }

And the more compact version of the above (assumes shorter parameter names, and only [in] or [out] params but no [in,out] params):

    /// \brief      A brief one or two line description of the function.
    /// \param[in]  variable_1  Input parameter
    /// \param[in]  variable_2  Another input parameter
    /// \param[out] variable_3  Output parameter
    /// \param[out] variable_4  Another output parameter
    /// \return     None
    void myFunc(int var1, int var2, int* var3, int* var4)
    {
        // function implementation here
    }


====================================================================================================
= bazel: =
====================================================================================================

Good example to get started in Bazel: https://github.com/ElectricRCAircraftGuy/eRCaGuy_gtest_practice

Config files:
1. BUILD (old, but still widely-used)
1. BUILD.bazel (new, but still not widely-accepted, and is somewhat debated) [see note 1 below]
1. WORKSPACE
1. .bazelrc in your workspace directory (next to the main WORKSPACE file); see: https://docs.bazel.build/versions/master/guide.html#where-are-the-bazelrc-files

Notes:
[1] GS: for all new projects, I recommend using `BUILD.bazel` over `BUILD`. See here:
    1. [In Docs: clarify BUILD vs. BUILD.bazel #4517](https://github.com/bazelbuild/bazel/issues/4517) - brings up the fact this is an on-going debate. 
    1. https://docs.bazel.build/versions/master/build-ref.html#packages - shows both as valid options: `BUILD.bazel` and `BUILD`.

Bazel Online Documentation:
1. See all Bazel commands here (ie: `bazel --[startup options] <cmd> --[cmd options]`): https://docs.bazel.build/versions/master/command-line-reference.html#commands
1. See all Bazel options online here! https://docs.bazel.build/versions/master/command-line-reference.html. Ex:
    1. Sub-categories of options:
        1. All `bazel build` options: https://docs.bazel.build/versions/master/command-line-reference.html#build-options
        1. All `bazel test`  options: https://docs.bazel.build/versions/master/command-line-reference.html#test-options
        1. All `bazel query` options: https://docs.bazel.build/versions/master/command-line-reference.html#query-options
        1. etc.
    1. To pass in Java Virtual Machine (JVM) options, such as heap size, as Bazel startup options: https://docs.bazel.build/versions/master/command-line-reference.html#flag--host_jvm_args
            --host_jvm_args=<jvm_arg>
    2. To limit how many of your local CPUs Bazel can use. Note that HOST_CPUS here is probably (and usually is) 1/2 the number of cores you have. So, if gnome-system-monitor shows you have 8 cores, you may only have 4 CPUs.: https://docs.bazel.build/versions/master/command-line-reference.html#flag--local_cpu_resources
            --local_cpu_resources=<an integer, or "HOST_CPUS", optionally followed by [-|*]<float>.> default: "HOST_CPUS"
        NB: THIS cpu resource limiter option above doesn't actually work very well! Frequently, even with it in-use, the CPU usage will still lock out at 100% for periods of many minutes at a time! To prevent this, just use the Linux `cpulimit` program in a separate terminal!:
            cpulimit -p <pid> -l 500 # limit your bazel build to 62.5% max CPU usage on an 8-core machine
        Read more about the above command in the "Limit CPU usage" section of this document down below.
    3. To limit local RAM usage: https://docs.bazel.build/versions/master/command-line-reference.html#flag--local_ram_resources
            --local_ram_resources=<an integer, or "HOST_RAM", optionally followed by [-|*]<float>.> default: "HOST_RAM*.67"
    4. To disable remote caching: https://docs.bazel.build/versions/master/command-line-reference.html#flag--remote_cache
            --remote_cache=""
    1. To share build outputs between users, for saving hard drive space, use bazel startup option:
            --output_user_root=<path>
       See: https://docs.bazel.build/versions/master/command-line-reference.html#flag--output_user_root
       Ex:
            bazel --output_user_root="/home/some_other_user/.cache/bazel" build //...
1. "A user's guide to Bazel" - https://docs.bazel.build/versions/master/guide.html
    1. Specifying targets to build (`bazel build //...` [build the whole project], `bazel build //:all` [build just the top-level build targets], etc.) - 
       https://docs.bazel.build/versions/master/guide.html#specifying-targets-to-build
1. Macros (Bazel build rule macros--used to generate build targets):
    1. Macros: https://docs.bazel.build/versions/master/skylark/macros.html
        1. Expanding macros: https://docs.bazel.build/versions/master/skylark/macros.html#expanding-macros. To see their expanded forms:
            time bazel query --output=build //path/to/my/target/... > out.txt  # Store the expanded form of all macros/build rules into out.txt
            subl out.txt  # open out.txt in Sublime Text 3
    1. Creating a macro: https://docs.bazel.build/versions/master/skylark/tutorial-creating-a-macro.html
1. Bazel "Make" Variables: *****https://docs.bazel.build/versions/master/be/make-variables.html
    1. Ex: `my_attr = "prefix $(FOO) suffix"` = insert the Bazel "Make" (GNU Make-like) variable `FOO` into this attribute.
    Bigger example, with a `genrule()` (https://docs.bazel.build/versions/master/be/general.html#genrule) which runs during `bazel build` to run some bash command-line call, during the build, to do something like auto-generate some files required as C++ `srcs` and headers later in the build, for example:

        # =================================
        # "src/module1/BUILD" file:
        # =================================

        # `py_binary()`: see: https://docs.bazel.build/versions/master/be/python.html#py_binary
        py_binary(
            name = "generate_files",
            main = "scripts/generate_files.py",
            srcs = [
                "scripts/generate_files.py",
                "scripts/do_xyz.py",
            ],
            deps = [
                "//some/module:py_library_rule",
            ],
        )

        # =================================
        # "src/module2/BUILD" file:
        # =================================

        # The Python script run by the genrule below will need to read in and parse all of these files
        filegroup(
            name = "data_files_for_genrule",
            srcs = [
                "data/file1.txt",
                "data/file2.csv",
                "data/file3.py",
                "yaml/yaml1.yaml",
                ":another_file_group",
            ],
        )

        # See what the variable-substituted version/output of this is with:
        #       bazel query --output=build //src/module2:run_this_python_script_during_build
        genrule(
            name = "run_this_python_script_during_build", # <== (that's what a genrule does!)
            srcs = [
                ":data_files_for_genrule",  # a filegroup from this same BUILD file
                "//some/package:another_filegroup",  # a filegroup from another package
                "data/file10.txt",  # a local file; relative path from this BUILD file's dir
            ],
            # Files not in this `outs` Starlark (Python3-like) list will be deleted by Bazel after
            # this genrule() runs, so any files which this script generates MUST be in this list
            # for them to persist and be available for later parts of this build! So, add all 
            # (generated-by-this-script) files to `outs` that you need to NOT be deleted by Bazel!
            outs = [
                "mymodule/autogen/file1.h",
                "mymodule/autogen/file1.cpp",
                "mymodule/autogen/file2.cpp",
                "mymodule2/autogen/file1.csv",
                "mymodule2/autogen/file1.yaml",
            ],
            # See meaning of `execpath`, used in this Bazel "Make" variable, here:
            # https://docs.bazel.build/versions/master/be/make-variables.html#predefined_label_variables
            cmd = (
                '$(execpath //src/module1:generate_files) '
                '--option1 "something" '
                '--option2 "something else" '
                '--option3 12973 '
                # Pass in all `outs` items to the script itself, if desired, to process. `OUTS` here
                # is a Bazel "Make" variable. 
                # See: https://docs.bazel.build/versions/master/be/make-variables.html
                '--bazel_outs "$(OUTS)" '
                # Pass in the Bazel `srcs` list too via this Bazel "Make" variable. See link above.
                '--bazel_srcs "$(SRCS)" '
            ),
            visibility = [
                "//visibility:private",
            ],
        )

    NOTES:
    In the `genrule()` above, you could also do the command like this:
            cmd = (
                # I *think* this path relative to the project root dir would work:
                '//src/module1/scripts/generate_files.py '
                # OR if the file was local to this module, just call it with a path relative to this module:
                'scripts/generate_files.py '
                # Instead of this:
                # '$(execpath //src/module1:generate_files) '
                '--option1 "something" '
                '--option2 "something else" '
                '--option3 12973 '
                '--bazel_outs "$(OUTS)" '
                '--bazel_srcs "$(SRCS)" '
            ),

    ...or like this, if you wanted to join the command as a list of strings (joined by a single 
    space) instead. Notice the deleted space before the ending single quote on each line, and the 
    added comma after the single quote to make this a list of strings now instead of a 
    continuous, multi-line string!
            cmd = ' '.join([
                '$(execpath //src/module1:generate_files)',
                '--option1 "something"',
                '--option2 "something else"',
                '--option3 12973',
                '--bazel_outs "$(OUTS)"',
                '--bazel_srcs "$(SRCS)"',
            ]),

    REFERENCES FOR THE ABOVE EXAMPLE:
    1. *****https://docs.bazel.build/versions/master/be/make-variables.html
    1. https://docs.bazel.build/versions/master/be/python.html#py_binary
    1. https://docs.bazel.build/versions/master/be/general.html#genrule
    1. https://docs.bazel.build/versions/master/be/general.html#filegroup
    1. EXAMPLE `genrule()` & BUILD file from Bazel, with a custom rule from a custom `defs.bzl` 
       file!: https://github.com/bazelbuild/examples/blob/master/make-variables/testapp/BUILD

1. `bazel query` example to show *exactly* what the above `genrule()` would look like AFTER full
   variable substitution into it:
        bazel query --output=build //src/module2:run_this_python_script_during_build
1. See what predefined Bazel "Make", and Bazel environment variables exist for your Bazel build environment. 
   See: https://docs.bazel.build/versions/master/be/make-variables.html#predefined_variables 
        bazel info --show_make_env [build options] = shows all predefined "Make" variables in all caps at the top, and bazel environment variables in lowercase thereafter
1. See here for details on the Bazel "output directory layout"!: https://docs.bazel.build/versions/master/output_directories.html
   See also the `bazel info` commands just below!

bazel info --show_make_env [optional: build options] = see just above! It shows all predefined Bazel "Make" variables in ALL CAPS at the very top, and then Bazel environment variables, such as genfiles, bin, etc. output and build paths right after that! See here for details on the Bazel "output directory layout"!: https://docs.bazel.build/versions/master/output_directories.html <==== VERY USEFUL TO BE ABLE TO SEE WHERE ALL BUILD OUTPUT WILL BE PLACED FOR A GIVEN SET OF BUILD SETTINGS! ====
bazel info = similar to the above, but show JUST the Bazel environment variables (output/build dirs and things), and NOT the Bazel "Make" variables as well! <==== VERY USEFUL! ====  
bazel info bazel-bin = show the full path to the bazel output "bin" directory

time bazel build //... = build the whole project
time bazel build //:all = (apparently) build only the build targets at the **top level** of the project (defined directly in the top-most BUILD or BUILD.bazel file), NOT recursing down and building all lower-level build targets too, like `bazel build //...` would do; see here for more info:
    https://docs.bazel.build/versions/master/guide.html#specifying-targets-to-build
time bazel query //...
time bazel test //...
bazel --version
bazel help
bazel help build

== bazel query: ==
References:
1. *****[START HERE] https://docs.bazel.build/versions/master/query-how-to.html
   Ex: see dependencies of a build target:
        bazel query 'deps(//path/to/package:target)'
1. *****https://docs.bazel.build/versions/master/query.html

bazel query = invalid command (missing arguments); it will tell you to type `bazel help query` for help
bazel help query = see the help for `bazel query`
bazel help query | less -RFX = same as above, but see the output in the less viewer since it's so long
bazel help --long query = show the long help menu
bazel help --long query | less -RFX = same as above, but see the output in the less viewer since it's so long <====== GOOD HELP INFO =====

FIND DEPENDENCIES OF A BUILD TARGET:
bazel query "deps(//foo)"
bazel query "deps(//some/path:my_target)"
bazel query "deps(//some/path/...)"
bazel query 'deps(//path/to/package:target)' = "find all dependencies of //path/to/package:target"

FIND A DEPENDENCY PATH BETWEEN TWO BUILD TARGETS:
bazel query 'somepath(//path/to/package:target, //dependency)' = "find a dependency path between //path/to/package:target and //dependency"

== SUMMARY OF GOOD STARTUP OPTIONS (see above or below or online for details): ==
bazel [startup_options] build //...
    --host_jvm_args=-Xmx16g
    --output_user_root="/path/to/custom/dir/bazel_cache"

== SUMMARY OF GOOD BUILD OPTIONS (see above or below or online for details): ==
bazel build [build_options] //...
    --keep_going
    --copt
    --per_file_copt
    --jobs

== BUILD WITH DEBUG SYMBOLS ==
[bazel debug builds; bazel build with gdb debug symbols; bazel gdb debug builds]

(required to debug an executable with gdb or lldb, for instance):
- gdb debugger: https://www.gnu.org/software/gdb/
- lldb debugger: https://lldb.llvm.org/
1) `--copt` build option:
bazel build --copt="-ggdb" --copt="-O0" //... = add C build options for gdb debugging symbols and Optimization Level 0 for the entire build! See: 
    1. *****+https://docs.bazel.build/versions/master/user-manual.html#flag--copt
    2. https://docs.bazel.build/versions/master/command-line-reference.html#flag--copt and
2) `copts` addition to the BUILD.bazel file:
- Alternatively, just do this for individual build targets, as desired, in `copts` for cc_library() rules; see here: 
https://docs.bazel.build/versions/master/be/c-cpp.html#cc_library.copts
Here is an example of how to use `copts`, partially pulled from the examples here:
https://docs.bazel.build/versions/master/be/c-cpp.html#cc_library

    cc_library(
        name = "bar",
        copts = [
            "-ggdb",  # <=======
            "-O0",    # <=======
        ],
        srcs = [
            "bar.cc",
            "bar-impl.h",
        ],
        hdrs = ["bar.h"],
        deps = [":baz"],
    )

3) BEST OPTION: USE the `--per_file_copt` BAZEL BUILD OPTION INSTEAD!
Documentation:
1. *****+https://docs.bazel.build/versions/master/user-manual.html#flag--per_file_copt
2. https://docs.bazel.build/versions/master/command-line-reference.html#flag--per_file_copt
bazel build --per_file_copt=path/to/my/module/.*@-ggdb,-O0 //... = build everything, but anything which matches the regular expression `path/to/my/module/.*` will also be built with the appropriate gdb debug symbols (`-ggdb`) and with optimization level zero (`-O0`) for easy debugging! You may also need to add `--strip=never` to keep the linker from stripping debug symbols during linking, like this:
bazel build --per_file_copt=path/to/my/module/.*@-ggdb,-O0 --strip=never //... = same as above, but never strip debugging symbols! See the link above, as well as this: https://docs.bazel.build/versions/master/user-manual.html#flag--strip
- - - 
More complicated, generic `--per_file_copt` example:
--per_file_copt=//foo:.*\.cc,-//foo:file\.cc@-O0,-fprofile-arcs = adds the `-O0` and the `-fprofile-arcs` options to the command line of the C++ compiler for all `.cc` files in [the build *target* path] `//foo/` except `file.cc`.

== == 

time bazel query --output=build //path/to/my/target/... > out.txt = Store the expanded form of all macros/build rules into out.txt; see above; see this too for more on **expanding Bazel build macros**: https://docs.bazel.build/versions/master/skylark/macros.html#expanding-macros 

bazel --host_jvm_args=-Xmx16g build //... = set max java heap size to 16g then build everything; see here for the command above, as well as for how to make a Linux swapfile! 
https://stackoverflow.com/questions/55190272/java-lang-outofmemoryerror-when-running-bazel-build/60572662#60572662

*****BEST BAZEL BUILD CMD*****
time bazel --host_jvm_args=-Xmx16g build //...; gs_alert = same as above but better: time the whole thing and do an alert sound (bell character sound) & pop-up notification to notify me when done     <============== OVERALL BEST BAZEL BUILD COMMAND ==========

Other useful options:
1) Specify a custom bazel cache directory (*bazel startup* option `--output_user_root`). Useful, for example, when you have limited space and need to A) put your build cache on another drive, or B) share a bazel build cache with another user, or even multiple users:
- See: https://docs.bazel.build/versions/master/command-line-reference.html#flag--output_user_root
        bazel --output_user_root="/path/to/custom/dir/bazel_cache" build //...
2) Specify the number of "jobs", or threads to run at once during the build (bazel *build* option `--jobs N`). The default is `--jobs=auto`, which tries to "[calculate] a reasonable default based on host resources":
- See: https://docs.bazel.build/versions/master/command-line-reference.html#flag--jobs
        bazel build --jobs 4 //...  # 4 jobs might be good on a 6-core machine, for instance, or perhaps 6 jobs on an 8-core machine, or 16 jobs on a 20-core machine--whatever you think is best for your situation; not using all the cores leaves some for you to continue working while a build is running in the background
#) Now, putting it all together:
        bazel --output_user_root="/home/gabriels/.cache/bazel_cache" build --jobs 4 //...'     <============ VERY USEFUL TO KNOW ABOUT ============

== BAZEL TEST OPTIONS: == 

bazel test --test_output=errors //... = log all errors (failed test results) to stdout--in other words, you'll only see a long output from running the bazel test if it fails!--this is a good setting to use; for help, see: https://groups.google.com/forum/#!topic/bazel-discuss/2mJPklIaCeo; see also: `bazel help test` for other options!
bazel test --test_output=summary //... = the default (doesn't show errors; just shows a summary)
bazel test --test_output=all //... = prints ALL output to stdout, even for tests that pass!

*****BEST BAZEL TEST CMD (optionally add `--host_jvm_args=-Xmx16g` if needed too)*****
time bazel test --test_output=errors --test_arg=--gtest_color=yes //... = get color output in the tests! See the readme in my project here for more explanation and a list of references: https://github.com/ElectricRCAircraftGuy/eRCaGuy_gtest_practice. See also: https://stackoverflow.com/questions/50877601/how-to-pass-custom-flags-to-bazel-test-command/50890446#50890446.

== Debugging Bazel Builds: ==
[bazel debug; *debugging bazel builds*; debug bazel builds; bazel builds debugging; bazel debugging]

`--keep_going` flag: useful when debugging--tells Bazel to keep going and build/run as much as possible, even if an error is encountered. See: https://docs.bazel.build/versions/master/command-line-reference.html#flag--keep_going. [keep going, keep building, continue building after errors, build through errors]. Ex usage:
    time bazel build --keep_going //... = keep going/building during a Bazel build/run error, so that you can get and see as many errors as possible at once to speed up the fix/build/test process as you try to debug build or test problems and get your code to work right. <========= VERY USEFUL!--ESP. WHEN DEBUGGING CODE THAT WON'T BUILD! ==========
`--sandbox_debug` flag: helps you see more build info. Ex usage:
    time bazel build --sandbox_debug //...
`-s` outputs all build commands [sort of like you might expect a "verbose" build option to do!?]; see: https://stackoverflow.com/questions/32823625/bazel-build-verbose-compiler-commands-logging/32837180#32837180. Ex usage:
    time bazel build -s //...

== Visualizing your Bazel build using dot/Graphviz ==
See:
1. Bazel info:
    1. https://blog.bazel.build/2015/06/17/visualize-your-build.html
    1. *****https://docs.bazel.build/versions/master/query-how-to.html
1. General dot/Graphviz info:
    1. https://www.graphviz.org/
    1. [Drawing graphs with _dot_](https://www.graphviz.org/pdf/dotguide.pdf)
    1. https://en.wikipedia.org/wiki/DOT_(graph_description_language)


====================================================================================================
= gdb and gdbgui: = 
====================================================================================================

== General: ==

1. If you need help locating your binary executable in your build output, try using `locate name_of_executable` to search your system for it.
1. Be sure to buld with debug symbols on: `-ggdb` and `-O0`, for instance, are recommended. `-g` and `-g3` may also work. For Bazel, see the `--per_file_copt` option described above to easily add these C build options in while building. Ex:
    time bazel build --per_file_copt=path/to/my/module/.*@-ggdb,-O0 --strip=never //...
  OR
    time bazel build --copt="-ggdb" --copt="-O0" --strip=never //...

== gdb: ==

References:
1. https://www.gnu.org/software/gdb/
1. https://en.wikipedia.org/wiki/GNU_Debugger
1. https://www.onlinegdb.com/
    1. http://www.gdbtutorial.com/ 
    1. https://www.onlinegdb.com/blog/brief-guide-on-how-to-use-onlinegdb-debugger/

Note: it is a good idea to launch gdb from your root source directory, ie: at the base directory where your source code begins, so that if your source code paths for your symbols are relative, gdb can automatically find your source code! Otherwise, it will say `No such file or directory.`

Also google for "gdb cheatsheet" to find helpful resources online. Ex:
[Google search for "gdb cheat sheet"](https://www.google.com/search?q=gdb+cheat+sheet&oq=gdb+cheat+&aqs=chrome.0.69i59j69i57j69i60l3.3061j0j4&sourceid=chrome&ie=UTF-8)
1. *****https://darkdust.net/files/GDB%20Cheat%20Sheet.pdf

TO LEARN:
1. Google "how to run crash dumps with GDB"
1. Google "core dump handler"

GDB USAGE:
1) Be sure to run gdb from the root of the source code so that all paths to the source code will work! Otherwise, paths may be broken and the source code may not be able to be displayed!
        cd /path/to/root/of/source/code
2) Run gdb, passing it the executable to load
        gdb /path/to/root/of/source/code/path/to/executable/compiled/with/debug/symbols/on
3) (Optional) Now press Ctrl + X, then A to enter the GUI/TUI (Textual User Interface) ncurses mode; see: https://undo.io/resources/gdb-watchpoint/5-ways-reduce-debugging-hours/
   Press Ctrl + 2 to cycle through 2-view modes. Press Ctrl + 1 to go back to 1-view mode. Press Ctrl + X, then A to exit or re-enter the TUI mode.
4) Add a breakpoint in main.cpp, at line 100 for instance
        break main.cpp:100
5) Run to that point, then wait about 3 to 5 seconds or whatever for it to run and stop at your break point
        run
6) Use gdb as desired; see the shortcuts and commands below and online on cheat sheets. The main ones are essentially this:
break file.cpp:100, r = run (restart from beginning), c = continue (until next break point), Ctrl + C = pause (send SIGINT interrupt to gdb), n = next (step over), s = step into, fin = finish (step up)

------------------------------------------------------
gdb_short_cmd (or long_cmd) (gdbgui keyboard shortcut)
------------------------------------------------------

See: https://undo.io/resources/gdb-watchpoint/5-ways-reduce-debugging-hours/
Ctrl + X, A = enter/exit ncurses user interface mode (TUI--Text User Interface)
Ctrl + 2 = cycle through 2-window TUI modes
Ctrl + 1 = return to 1-window TUI mode

break main.cpp:100 = set a break point in main.cpp at line 100
b main.cpp:100 = same as above
bt = backtrace: display the program stack (AKA: stack trace or stack frames)
up = go up to higher stack frame
down = go down to lower stack frame

r (or run) = run (start from beginning)
c = continue until breakpoint
Ctrl + C = send SIGINT interrupt signal to gdb to pause gdb and let you interact with it
n (or right arrow) = next (step over)
s (or down arrow) = step into
fin (or finish) (u) (or up arrow) = step out or up out of a lower-level function or scope; see: 
    https://unix.stackexchange.com/questions/297982/how-to-step-into-step-over-and-step-out-with-gdb and
    https://stackoverflow.com/questions/24712690/step-out-of-current-function-with-gdb/24712736#24712736
m = execute one machine instruction, stepping OVER function calls
, = execute one machine instruction, stepping INTO function calls

STILL NEED TO STUDY & LEARN THESE ONES:
print <var_name>
display <var_name>
delete = delete all breakpoints?
delete 1 = delete the 1st breakpoint

== gdbgui: ==

References:
1. https://www.gdbgui.com/
    1. Lots of great usage details in the screenshot tour! https://www.gdbgui.com/screenshots/
    1. Examples: https://www.gdbgui.com/examples/
    1. FAQ: https://www.gdbgui.com/faq/
        - esp. see the section titled "How do I make program output appear in a different terminal?"
1. GitHub: https://github.com/cs01/gdbgui/

Installation:
See: https://www.gdbgui.com/installation/
In short:

    python3 -m pip install --user pipx
    python3 -m userpath append ~/.local/bin
    pipx install gdbgui

If you're missing any dependencies, you may get a warning. Install those as well. 

To upgrade:

    pipx upgrade gdbgui

To uninstall:

    pipx uninstall gdbgui

Keyboard shortcuts: see (gdbgui keyboard shortcut) above.

USAGE:
- see the Examples in the References above.
1) Load the gdbgui server
gdbgui -h     = help menu
gdbgui --help = help menu
gdbgui = most basic usage; do auto-open a browser
gdbgui -r --project="/path/to/root_execute_dir" --remap-sources='{"/old/base/path": "/path/to/root_execute_dir"}' --gdb-args="--tty=$(tty)" = run the gdbgui server on a remote machine (-r, so don't auto-open a browser), setting the root dir for all source (--project) files to "/path/to/root_execute_dir", and remapping all source code paths from "/old/base/path/whatever.cpp" to the correct source code location on the remote machine of "/path/to/root_execute_dir/whatever.cpp". The `--gdb-args="--tty=$(tty)"` part at the end is a work-around for a [bug](https://github.com/cs01/gdbgui/issues/333), to redirect all stdout (ex: from `printf()`-type statements) to the terminal in which you launch `gdbgui`, so that it won't get lost and not published in the `gdbgui` either. This is the bug report: https://github.com/cs01/gdbgui/issues/333. Just be sure to watch for all stdout messages in the terminal where you launched gdbgui instead of in the console in the gdbgui in the browser!
2) In the "Load Binary" box at the top, type in the path to the binary (use the path from the *remote* machine's perspective if gdbgui is running on a remote machine): "/path/to/root_execute_dir/my/binary", and click "Load Binary". Now it will automatically load and display the source code, so long as you compiled it with `-g` (ok), `-g3` (better), or `-ggdb` (best I think), AND you properly set up your `--remap-sources` option, if required.  
3) Click the "Run" button (the far left of the 6 buttons in the top-right of the browser window), and wait up to 5 or 6 seconds or so for the binary to begin executing. 
4) Now debug with the 6 main buttons in the top-right, and be sure to watch the *terminal* from which you launched gdbgui for all stdout (`printf()`-like) output if you have used the `--gdb-args="--tty=$(tty)"` option. Otherwise, the output will be right inside the console at the bottom of the gdbgui. 

Here's some gdbgui debug tips:
- Learn more in the screenshot tour here: https://www.gdbgui.com/screenshots/
- and in the FAQ here: 
    1. Hover your mouse over the code to see clickable links and pop-up information on functions and variables and things. 
    2. Use the search bar at the left to do a hash-table-based fuzzy search lookup of any source files, in order to load them. The root path it shows here is what your `--project=` option configured above.
    3. Use the gdb input text bar at the very bottom of the screen to input any gdb command manually. This gives you FULL access to ALL gdb commands, even those which are not integrated into the gui otherwise. 
    4. In the right-hand panel you have a bunch of options. You can select threads and view the stack trace of the threads, for instance.
The gdbgui tool makes gdb much more intuitive and easy to use!


====================================================================================================
= googletest (gtest) / googlemock (gmock): = 
====================================================================================================

See the "eRCaGuy_dotfiles/googletest" directory, **especially** the "eRCaGuy_dotfiles/googletest/insights.md" file, which has a bunch of my own personal documentation, notes, and insights!

== test (`TEST() {}`, `TEST_F() {}`) order: == 

You can NOT rely on google tests to be run in any particular order. Also, the order can be shuffled with `--gtest_shuffle`; see: https://github.com/google/googletest/blob/master/googletest/docs/advanced.md#shuffling-the-tests


====================================================================================================
= linters, Static Code Analyzers, clang-format, etc.: = 
====================================================================================================
[linters, clang-format]

GENERAL LIST OF TOOLS:
NAME                LANGUAGE
------------        -------------
clang-format        C/C++
clang-tidy          C/C++
clang sanitizers    C/C++
shellcheck          Linux/Posix shell: bash/sh, etc. <=== really useful!
flake8              Python
black               Python (https://pypi.org/project/black/)
pylint              Python (https://pypi.org/project/pylint/)
roslint             Python (for ROS packages?) (http://wiki.ros.org/roslint)
yamllint            YAML (https://yamllint.readthedocs.io/en/stable/quickstart.html) (http://www.yamllint.com/)
buildifier          Bazel BUILD/*.bzl files (https://github.com/bazelbuild/buildtools/tree/master/buildifier)

== clang-format: ==
[C/C++]

A source code automatic style formatting tool for C and C++.

References:
1. Main documentation, setup, instructions, etc! https://clang.llvm.org/docs/ClangFormat.html
2. Download the Windows & other installers/executables: https://llvm.org/builds/
3. Clang-Format Style Options: https://clang.llvm.org/docs/ClangFormatStyleOptions.html

Install in Ubuntu with `sudo apt install clang-format`; source (note I also have an answer here): https://stackoverflow.com/questions/20756924/how-can-i-install-clang-format-in-ubuntu

Help:
    clang-format --help
    man clang-format

To generate a .clang-format file as a starting point:
-See: https://clang.llvm.org/docs/ClangFormat.html
    clang-format --style=llvm --dump-config > .clang-format
    OR
    clang-format --style=google --dump-config > .clang-format

Main clang-format tools & commands include:
    clang-format [options] [<file> ...] = the main command; see: https://clang.llvm.org/docs/ClangFormat.html
    
    clang-format-diff = a python script that allows you to format a git diff patch; see: https://clang.llvm.org/docs/ClangFormat.html
    
    git clang-format = a tool blended in with git to allow you to format just the lines you touched before you git commit them [GS: I don't like this work-flow; I'd rather do a commit and THEN go back and run a command to format *the entire file* for any file I touched, instead. Then, I'll make that format run a separate commit.]

Example usages:
    clang-format --style=google my_file.cpp > my_file_formatted.cpp = format a file and send the output to a separate file, using a preconfigured style
    clang-format -i --style=google my_file.cpp = format this file in-place!
  Use `--verbose` to also print the file names processed!
    clang-format -i --verbose --style=google my_file.cpp = same as above, but print the name of the file processed (particularly useful when you have a script which processes many files and you want the user to see as output a list of the files processed!)
  Use `--style=file` to "load style configuration from .clang-format file located in one of the parent directories of the source file (or current directory for stdin)".
    clang-format --verbose -i --style=file my_file.cpp = format my_file.cpp in place, using the .clang-format file located in one of the parent directories of the source file, printing the name(s) of the file(s) processed. <======= BEST OPTION FOR MANUALLY-SPECIFIED FILE(S)! =======
    clang-format --verbose --style=file my_file.cpp | diff -u --color=always my_file.cpp - = do a PREVIEW of the command just above! ie: run the clang-formatter with the same commands, except NOT modifying the file 'i'n-place, and send the output to stdout (which is the default of clang-format), where it will then be piped via stdin to the `diff` command as the right file (-) to compare to the left file, which is the original my_file.cpp! In this way, you've manually created a means of PREVIEWING a clang-format change to see what changes WILL be made, withOUT actually making these changes! See the == diff: == section below for further details. <========= BEST **PREVIEW** COMMAND FOR CLANG-FORMAT! =========
  See here for where I've used clang-format in a project before! 
    https://github.com/AmboVent-1690-108/AmboVent/blob/master/3-Software/Arduino/run_clang-format.sh
    And it's format file:
    https://github.com/AmboVent-1690-108/AmboVent/blob/master/3-Software/Arduino/.clang-format

Whenever I do a `git commit`, however, I'd like to format *all parts of all files I have touched*. To do this, you can see which files were changed between two commits like this:
    git diff --name-only commit1~..commit2  # Note that the tilde (~) is required to specify the commit *before* commit1, because otherwise commit1 would *not* be included in determining which files were changed.
Then you can manually clang-format all of those files, OR (I think--needs to be tested), you can automate the process like this:
    clang-format --verbose -i --style=file $(git diff --name-only commit1~..commit2)  <======= NEEDS TO BE TESTED, BUT SHOULD BE THE BEST OPTION FOR AUTOMATICALLY-SPECIFIED FILES! ======

== clang-tidy: ==
[C/C++]

A source code static analysis (programming errors, style, best practices, bug checker) tool.

References:
1. https://clang.llvm.org/extra/clang-tidy/ 

== clang sanitizers: ==
[C/C++]

Sanitizers are built into the clang (LLVM) compiler, and designed to find problems, such as undefined behavior. 

1. There are a bunch of sanitizers; see them all here: https://clang.llvm.org/docs/index.html; search this page for "sanitizer"; ex:
    1. https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html
        1. Finds undefined behavior, such as signed overflow
    1. https://clang.llvm.org/docs/AddressSanitizer.html
        1. Finds address problems, such as use after free, out of bounds access, double free, etc.
    1. https://clang.llvm.org/docs/ThreadSanitizer.html
        1. Detects data races. 
    1. https://clang.llvm.org/docs/MemorySanitizer.html
        1. Detects uninitialized reads.
    1. etc.

Example of using the undefined behavior sanitizer:
- Read more here: https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html
Normal clang build command for a single-file project, test.cc:
    clang++ test.cc  # build it
    ./a.out          # run it
And now building the same project, but "sanitizing" for (looking for) undefined behavior:
    clang++ -fsanitize=undefined test.cc  # build it in sanitize mode
    ./a.out  # run it
    # Results: undefined behavior found while running the application!
    #       test.cc:3:5: runtime error: signed integer overflow: 2147483647 + 1 cannot be represented in type 'int'

== shellcheck: ==
[Linux/Posix shell/sh/bash]
- bash/shell script file checker/linter; 
- **VERY HELPFUL** when writing bash (or other Linux shell) scripts!

REFERENCES:
1. https://www.shellcheck.net
1. https://github.com/koalaman/shellcheck

shellcheck -x file1.sh file2.sh file3.sh
shellcheck --external-sources file1.sh file2.sh file3.sh = same as above
optionally use `-e ERR_CODE1,ERR_CODE2,ERR_CODE3` to ignore ('e'xclude) certain 'e'rror codes that `shellcheck` might otherwise output, but that you don't care about; see `man shellcheck` for details! Ex:
shellcheck -x -e CODE1,CODE2,CODE3 file1.sh file2.sh file3.sh = see explanation just above

== Python linters (General): ==
[Python]

REFERENCES:
1. https://realpython.com/python-code-quality/
1. https://dbader.org/blog/python-code-linting

== flake8: ==
[Python]
*****If in doubt, just start here when it comes to choosing a Python linter! It seems to be the most-recommended and the easiest to get started with.

REFERENCES:
1. https://flake8.pycqa.org/en/latest/

python3 -m pip install flake8
flake8 some/folder/myfile.py
flake8 some/folder/

== black: ==
[Python]

https://pypi.org/project/black/

== yamllint: ==
[yaml]

REFERENCES:
1. http://www.yamllint.com/
1. https://yamllint.readthedocs.io/en/stable/quickstart.html
1. https://yamllint.readthedocs.io/en/stable/configuration.html - learn how to set up your .yamllint configuration file here!

yamllint myfile.yaml = lint myfile.yaml
yamllint -c path/to/.yamllint myfile.yaml = lint myfile.yaml according to the config rules declared in your "path/to/.yamllint" config file; see more here for a default config file and info on how to use and configure it! https://yamllint.readthedocs.io/en/stable/configuration.html.
yamllint -c .yamllint myfile.yaml = same as above, but specify the path to the ".yamllint" config file to be right here in the current directory we are in!
yamllint -c myfile.yaml = same as above, but "look for a configuration file in the [default] locations (by order of preference)". See: https://yamllint.readthedocs.io/en/stable/configuration.html. The first place it looks is for a ".yamllint" file in the current working directory, for instance. 
    UPDATE: actually, I think you must simply leave off the `-c` to get the default behavior it describes on where it will search for a config file. Sooo, do this instead (I think):
yamllint myfile.yaml = correct form (I think) to get the default behavior described just above.


====================================================================================================
= tmux: = 
====================================================================================================

EXCELLENT how-to video! https://www.youtube.com/watch?time_continue=5&v=BHhA_ZKjyxo&feature=emb_logo
EXCELLENT SHORTCUTS & CHEAT-SHEET!: https://gist.github.com/MohamedAlaa/2961058  <=========

tmux = create a new tmux session
tmux new = same as `tmux`
tmux new -s <session_name> = create a new tmux session called "session_name"
tmux ls = list open tmux sessions
tmux list-sessions = same as `tmux ls`!
tmux attach -t <session_num> = re-attach back to 't'arget session session_num!   <===== ATTACH!
tmux a -t <session_num> = same as above ("a" is an alias for "attach")
tmux a = attach the only available session (assuming only one is available) <======= MY MOST COMMON USAGE!
tmux kill-session -t <session_name_or_num> = kill this session! (or, you can just attach to it then type `exit` repeatedly until it's all exited/killed)
tmux rename-session [-t current_name] [new_name] = rename a tmux session! See: https://superuser.com/questions/428016/how-do-i-rename-a-session-in-tmux/428025#428025 

exit = exit the window

Ctrl + B, then <cmd> = have tmux run <cmd>:  <=======
== LIST OF CMDS: ==
:<manual_cmd> = run <manual_cmd>
:split-window = do horizontal split (same as " below!)
=== Windows: ===
c = create window
, = rename window
p = previous window
n = next window
w = list windows
=== Panes (splits): ===
% = vertical split
" = horizontal split
o = swap panes [ie: change from one pane to another, within the same window]
x = kill pane
=== Sessions: ===
d = detach session (leaving it running on the server)!                                  <===== DETACH!
$ = rename current session

tmux source-file ~/.tmux.conf = (unconfirmed--maybe is the wrong command?) re-source your ~/.tmux.conf tmux config file to bring in its latest changes! See here: https://sanctum.geek.nz/arabesque/reloading-tmux-config/
tmux source ~/.tmux.conf = (try this instead maybe--looks more legitimate!) same as above apparently--need to try it out still; see here: https://unix.stackexchange.com/questions/66606/tmux-not-sourcing-my-tmux-conf/66607#66607; has lots of upvotes, so looks more legitimate

====================================================================================================
= git: = 
====================================================================================================

General References:
1. Stack Overflow (do general searches)
2. [GitHub git cheat sheet](https://github.github.com/training-kit/downloads/github-git-cheat-sheet/)

git alias = print out all of your aliases you have defined in your config file(s), such as in "~/.gitconfig" (or locally in a single repo I think too, in "/path/to/myrepo/.git/config")

"git-" + [TAB] [TAB] = see all programs or commands in your PATH (from git directly OR custom or 3rd-party git programs) whose names begin with "git-" (convention: name + the dash symbol), such as "git-alias". These programs can automatically be run withOUT the dash, because git automatically searches your PATH for this naming convention and makes them available. Therefore, a program named "git-alias", for example, can be run as `git alias`, withOUT the dash! [git-whatever]
See here for where I first learned this: http://barkas.com/2018/git-alias-bash-functions-with-arguments/#git-alias-in-your-path

git branch -a = show ALL branches, even remote-only branches
git branch -r = show ONLY 'r'emote branches
git branch -r | grep gabriel.staples = show all of my remote branches (which, by my convention, begin with "gabriel.staples_")
git branch -d -r origin/mybranch = delete remote branch; see: https://stackoverflow.com/questions/5094293/git-remote-branch-deleted-but-still-it-appears-in-branch-a/5096739#5096739
git branch -rd origin/mybranch = same as above

git add -A = add (stage changes for) all changes and files, including new files or actions to delete files
git add . = add (stage changes for) only those files which are already tracked (have been previously commited)
git add --patch <filename> = interactively add hunks/parts/chunks of filename, as desired! See here: https://stackoverflow.com/questions/1085162/commit-only-part-of-a-file-in-git/1085191#1085191
git add -p <filename> = same as above
git gui = open the GUI tool to do things like stage hunks, lines, or files; very useful for breaking up diffs/PRs! See: https://stackoverflow.com/questions/1085162/commit-only-part-of-a-file-in-git/1085202#1085202

git diff = look at all **unstaged** changes (those NOT yet added with `git add`)
git difftool = same as above, except view the changes in your "git difftool" (ex: meld) instead of via the `git diff` command line

git diff --cached = look at just the **staged** changes (those added with `git add`)
git difftool --cached = same as above, except view the changes in your "git difftool" (ex: meld) instead of via the `git diff` command line

git diff --name-only commit_hash = only see a list of changed files by filename
git diff --name-status commit_hash = [MUCH MORE USEFUL THAN THE CMD ABOVE!] see a list of filenames and status! Ex: indicators for modified, deleted, added, etc.

git log = show the git log history
git lg = show the git log history in a condensed form, with graphics lines to show forks, branches, and merges
    See: "eRCaGuy_dotfiles/home/.gitconfig" for how to create this `lg` alias for git, and 
    https://coderwall.com/p/euwpig/a-better-git-log for where I originally got it from!

git log --follow <one_single_filename> = [VERY USEFUL!] Show the `git log` history which affected JUST THIS ONE SINGLE FILE YOU TOLD IT TO FOLLOW! This is VERY helpful to track and follow all of the commits which touched a certain file, in order to go back commit by commit until you find out **which commit** introduced the changes to that file that you care about! 
    See: https://github.github.com/training-kit/downloads/github-git-cheat-sheet/ and `man git log` (then search for "--follow")
    [keywords: show file history]
git log --follow some/file/name | grep --color=always commit | head -n 10 = output just the FIRST 10 commits, hashes ONLY (ie: only the line containing the word "commit"), which have changed file some/file/name; ex:
    $ git log --follow "git & Linux cmds, help, tips & tricks - Gabriel.txt" | grep --color=always commit | head -n 10
    commit c6b9afa08d2b54ac80de3a5348f2d3455755a2b3
    commit c15c92170a00481c2a0f2fed9293e29b3209f3fd
    commit 47707a49d2789f218ae1b0a12e46e9c447a5b546
    commit bcd1674fb2576dd5ae8c0bc040496a087650f03a
    commit 4a01aa865add7bfe216ed408d2ea35c79704b59b
    commit f28e233e2e6727c60e6b2e6c6bba620515ecc41b
    commit ca451665a170a277aecc244bd76d98623b864590
            git show <commit_hash>
    commit 343f51041afcbc0984a123bc6e72d21c60cd95ce
    commit 3583e6d05b5505e9c40d00ade448bd1a3ba3e11d
- But, notice the extraneous "commit" keyword was picked up above, so remove it by forcing a search for the word "commit" followed by a 30+ char hex-only hash! Add `-E` for extended regex search, and `[0-9a-f]{30,}` to find 30 or more chars in a row which are 0-9 or a-f (lower-case hex chars)!
git log --follow "git & Linux cmds, help, tips & tricks - Gabriel.txt" | grep -E --color=always "commit [0-9a-f]{30,}" | head -n 10 = does the above! <====== EXCELLENT; WORKS GREAT! ======
  Ex:
    $ git log --follow "git & Linux cmds, help, tips & tricks - Gabriel.txt" | grep -E --color=always "commit [0-9a-f]{30,}" | head -n 10
    commit c6b9afa08d2b54ac80de3a5348f2d3455755a2b3
    commit c15c92170a00481c2a0f2fed9293e29b3209f3fd
    commit 47707a49d2789f218ae1b0a12e46e9c447a5b546
    commit bcd1674fb2576dd5ae8c0bc040496a087650f03a
    commit 4a01aa865add7bfe216ed408d2ea35c79704b59b
    commit f28e233e2e6727c60e6b2e6c6bba620515ecc41b
    commit ca451665a170a277aecc244bd76d98623b864590
    commit 343f51041afcbc0984a123bc6e72d21c60cd95ce
    commit 3583e6d05b5505e9c40d00ade448bd1a3ba3e11d
    commit 00138466c643736cecc6f26e5255a6180a950890
- Now, to see what changes a given commit has done to this file, do this!
    git difftool commit_hash~..commit_hash some/file/name
  Ex:
    git difftool c6b9afa08d2b54ac80de3a5348f2d3455755a2b3~..c6b9afa08d2b54ac80de3a5348f2d3455755a2b3 "git & Linux cmds, help, tips & tricks - Gabriel.txt"
- Better than all of the above, use this script: "eRCaGuy_dotfiles/useful_scripts/git-filechange-search.sh"
  Examples: <=============== BEST WAY TO SEARCH FOR WHICH COMMIT CAUSES A GIVEN CHANGE ============
    gs_git-filechange-search "git & Linux cmds, help, tips & tricks - Gabriel.txt" = display a list of all commit hashes which change this file
    gs_git-filechange-search -v "git & Linux cmds, help, tips & tricks - Gabriel.txt" = same as above, but 'v'erbose (ie: also print out the commit log headers for these commits)
    gs_git-filechange-search -vv "git & Linux cmds, help, tips & tricks - Gabriel.txt" = same as above, but extra 'v'erbose
    gs_git-filechange-search "git & Linux cmds, help, tips & tricks - Gabriel.txt" "difftool" = display only those commits which change this file AND contain changes which contain the word "difftool"
    gs_git-filechange-search -v "git & Linux cmds, help, tips & tricks - Gabriel.txt" "difftool" = same as above, but 'v'erbose (ie: also print out the commit log headers for these commits)
    gs_git-filechange-search -vv "git & Linux cmds, help, tips & tricks - Gabriel.txt" "difftool" = same as above, but extra 'v'erbose

git log --author="name or email regex search pattern" = show an abridged git log with ONLY commits by an author which matches this regex search pattern. Ex:
    git log --author="Gabriel Staples"
    git log --author="some_email@gmail.com"

git show <commit_hash> = show the commit message that was stored, as well as a `git diff` of the changes this commit introduced, and to which files! 
    See: https://github.github.com/training-kit/downloads/github-git-cheat-sheet/

git cherry-pick <commit_hash> = cherry-pick (apply) commit_hash onto your currently-checked-out branch
git cherry-pick <commit_start>..<commit_end> = cherry-pick (apply) the range of commits from commit_start (NOT including this commit) to commit_end (including this commit); very useful in place of a rebase onto latest master once you have landed/merged some upstream commits into master and don't want to have to unnecessarily deconflict them via the `git rebase` process now instead; see: https://stackoverflow.com/questions/1994463/how-to-cherry-pick-a-range-of-commits-and-merge-into-another-branch/1994491#1994491
git cherry-pick commit_start~..commit_end = same as above, except **inclusive**! ie: cherry-pick (apply) the range of commits from commit_start (including this commit) to commit_end (also including this commit); see: https://stackoverflow.com/questions/1994463/how-to-cherry-pick-a-range-of-commits-and-merge-into-another-branch/1994491#1994491
git cherry-pick commit_start^..commit_end = alternative form of the above line--does the exact same thing
git cherry-pick commit1 commit2 commit3 = cherry-pick these commits (up to any number--add as many commit hashes as you want!) onto the current branch; NOT the same as using commit1..commit2, which selects a **range** of commits from 1 commit after commit1, through commit2!

== `git ls-files` and `git ls-tree`: ==

HOW TO LIST (ls) FILES IN A GIT REPO: `git ls-files` and `git ls-tree`

References:
    - `man git ls-files`: https://git-scm.com/docs/git-ls-files
    - `man git ls-tree`: https://git-scm.com/docs/git-ls-tree

1. GIT LS-FILES:

git ls-files = list (`ls`-like) all files in the git repo in the directory you are currently in
cd $(git rev-parse --show-toplevel) = cd into the absolute path of the top-level (root) of this git repo; see: https://stackoverflow.com/questions/957928/is-there-a-way-to-get-the-git-root-directory-in-one-command/957978#957978
cd $(git rev-parse --show-toplevel) && git ls-files = list all files in this git repo
git ls-files | wc -l = count all files in this repo, at this dir level or lower

find | wc -l = count all files in this directory or lower, including those NOT part of the checked-in files to this repo, and including all .git hidden metadata files to describe the branches and content of this repo; so...kind of similar to the above, except counting MORE than what is actually checked-in to this repo!

2. GIT LS-TREE:

git ls-tree -r HEAD = list (`ls`-like) all files in the git repo in branch/commit HEAD in the directory you are currently in
    See: https://stackoverflow.com/questions/277546/can-i-use-git-to-search-for-matching-filenames-in-a-repository/277557#277557
git ls-tree --full-tree -r HEAD = same as above, except list ALL files in the repo, as if you were in the repo's root dir when making this call
cd $(git rev-parse --show-toplevel) && git ls-tree -r HEAD = same effect as the above, simply by `cd`ing into the repo's root dir first.
git ls-tree -r HEAD | wc -l = same as `git ls-files | wc -l`: count all files in this repo, at this dir level or lower
git ls-tree --full-tree -r HEAD | wc -l = count all files in this repo, period
cd $(git rev-parse --show-toplevel) && git ls-tree -r HEAD | wc -l = same as above, but in a different way; count all files in this repo, period

git ls-tree -r HEAD | grep "my_filename" = search for file "my_filename" in branch/commit HEAD at this dir level or lower <========= VERY USEFUL! =========
git ls-tree --full-tree -r HEAD | grep "my_filename" = search for file "my_filename" in branch/commit HEAD in ALL dirs! <========= VERY USEFUL! (MORE THOROUGH) =========
git ls-files | grep "my_filename" = same as above, except no need to explicitly set the branch/commit you'd like to search in! (It just searches the currently-checked-out branch/commit you're in). <========= VERY USEFUL! (MY FAVORITE) =========
    See: https://stackoverflow.com/questions/277546/can-i-use-git-to-search-for-matching-filenames-in-a-repository/24289481#24289481

3. To find a long-lost file that could be in ANY of your repo's branches or commits!
    See: https://stackoverflow.com/questions/277546/can-i-use-git-to-search-for-matching-filenames-in-a-repository/34100574#34100574
    and the gist it references: https://gist.github.com/dirkjot/073ffac502567e32f7ad
    - It relies on `git rev-list --all` as well as `git ls-tree --full-tree -r COMMIT | grep "search_term"`, and is quite ingenious and useful!

4. Related:
git rev-list --all = list all commits in reverse-chronological order which are traceable from your currently-checked-out commit...I think?
git rev-list HEAD --max-count=10 = list only the last 10 commits in reverse-chronological order which are traceable starting from "parent commit" HEAD; note that this is identical to doing `git log` (or `git lg`) and then looking back at ONLY the commit hashes for ONLY the last "--max-count" commits!

== ==

git merge-base branch1 branch2 = find the common ancestor between branch1 and branch2; see: https://stackoverflow.com/questions/1549146/git-find-the-most-recent-common-ancestor-of-two-branches/1549155#1549155

Assuming you just did this to rebase your feature branch onto latest master:
    git checkout master
    git pull origin master
    git checkout my_branch
    git rebase master  # or `git rebase -i master` to do it interactively
THEN HERE'S HOW TO COMPARE A JUST-REBASED BRANCH (`my_branch`) TO ITS OLD BACKUP (`my_brank_BAK`) FROM BEFORE REBASING (or rebasing + cherry-picking):  
[keywords: post-rebase compare, after-rebase compare, after rebase compare, compare files after rebase]  
(Assuming you're still on the newly-rebased branch `my_branch`):
    git difftool my_branch_BAK $(git diff --name-only $(git merge-base my_branch_BAK master) my_branch_BAK) = description: the inner-most $() finds the merge-base between the backup branch and the old master, and the outer $() finds the *list of filenames* which changed from that merge-base to the backup branch. This way, we end up `difftool`ing between the backup branch and the rebased branch, ONLY LOOKING AT THE FILES WE KNOW WE HAD PREVIOUSLY CHANGED!
  Better (easier to read):
    BRANCH_BAK=my_branch_bak && git difftool $BRANCH_BAK $(git diff --name-only $(git merge-base $BRANCH_BAK master) $BRANCH_BAK) <======= QUICKLY CHECK NEWLY-REBASED BRANCH AGAINST ITS BACKUP BRANCH! ======= [be sure to change `master` near the end to whatever upstream you have if necessary too!] <=======
   UPDATE: USE THIS SCRIPT INSTEAD NOW!: "eRCaGuy_dotfiles/useful_scripts/git-changes.sh".
    git changes <common_base> <backup_branch> [any other args to pass to git difftool]
   Ex:
    git changes master my_branch_bak <===== BEST! ======
  OR, if you're not on the newly-rebased `my_branch` anymore:
    git difftool my_branch_BAK..my_branch $(git diff --name-only $(git merge-base my_branch_BAK master) my_branch_BAK)

man git commit
git commit --date "Wed Jan 01 23:00:00 2020 -0700"
    - See `git log` for what various date formats look like

git push origin my_local_branchname:my_remote_branchname = push my_local_branchname to origin/my_remote_branchname; normally `git push`ing only allows pushing to a remote branch of the *same* branch name, so this is the work-around! See: https://stackoverflow.com/questions/13897717/push-commits-to-another-branch/13897766#13897766.

== To *locally* view, review, and compare changes from a GitHub PR, in the (fantastic) "meld" file comparison tool: ==  
[keywords: github review PR, github local review in meld, local github review in meld, github review locally, locally review github PR, local github PR review in meld]  
Note: despite being able to locally view the changes, you'll still have to use the GitHub interface for all comments and things in the review process. 

A) *Locally* look at changes in meld from a GitHub PR:  <========= VERY USEFUL FOR REVIEWING GITHUB PRs! ===========
1. Set up `meld` as your `git difftool`: https://stackoverflow.com/questions/14821358/git-mergetool-with-meld-on-windows/48979939#48979939
2. See the changes in meld as your `git difftool`:
    # 1) 
    git fetch --all
    # OR, if on a HUGE repo with thousands of branches, `git fetch --all` can take a long time (1 to 2+ minutes), so instead just fetch the 2 branches you need to check out: 1) the remote branch of interest from the GitHub PR, and 2) the latest remote master
    git fetch origin branch_from_github_PR master
    # 2) Then check out this remote GitHub branch locally (ie: check out your locally-stored remote-tracking branch [of this branch] which just got updated by the `fit fetch` above!)
    git checkout branch_from_github_PR
    # 3) This allows you to see all changes introduced by this feature branch, as compared to the 
    # original origin/master the author last rebased against or merged into their feature branch!
    git difftool $(git merge-base origin/master HEAD)   <========= VERY USEFUL FOR REVIEWING GITHUB PRs *in meld*! =========== 
    # OR: more explicitly stated, and required to be this way in case the GitHub PR is trying to merge into a different base:
    MERGE_INTO=origin/master && git difftool $(git merge-base $MERGE_INTO HEAD)   <========= VERY USEFUL FOR REVIEWING GITHUB PRs *in meld*! =========== 
- Optionally, see the *names of files changed* with this:
    git difftool --name-only $(git merge-base origin/master HEAD)
- And the *number of files changed* with this:
    git difftool --name-only $(git merge-base origin/master HEAD) | wc -l
- And the *commit hashes* for all commits that created the feature branch (where I learned about `git cherry`: https://stackoverflow.com/questions/7566416/how-to-see-which-commits-in-one-branch-arent-in-the-other/7566523#7566523; also sort of related (my own ans): https://stackoverflow.com/questions/7566416/how-to-see-which-commits-in-one-branch-arent-in-the-other/60731900#60731900):
    git cherry $(git merge-base origin/master HEAD) HEAD
- And the *commit hashes PLUS commit message subject lines* for all commits that created the feature branch, add `-v`:
    git cherry -v $(git merge-base origin/master HEAD) HEAD
- Why do the `git merge-base` part of the above? Because if you don't, then the `origin/master` that they recently merged into their PR to fix merge conflicts may NOT be the same `origin/master` you just pulled (yours is *newer*). If your `origin/master` you just pulled contains a bunch of newly-landed PRs from other people working simultaneously, for instance, then doing `git difftool master` alone, or `git difftool origin/master`, will be IN THE FUTURE, and you'll be `git diff`ing against FUTURE CHANGES that the PR in question doesn't even know about! Therefore, instead of seeing the true 5 or 10 files changed or whatever, you could see hundreds or even thousands of files changed from these future commits which occurred AFTER the PR requester last merged origin/master into their feature branch. 
-- To verify this and get more insight into it, you can manually `git merge origin/master` into their feature branch on your local machine, and then `git difftool origin/master` will work correctly, and so long as you did a `git merge-base origin/master branch_from_github_PR` BEFORE merging the latest origin/master into their feature branch (and copied and saved the output hash for your future reference), `git lg` will allow you to track back to that merge-base (manually search for it in `git lg` with the forward slash tool (/)), and you'll be able to see what's going on in all of the forks and splits and how far into the FUTURE `git difftool origin/master` was looking! 
-- So, to just avoid all this hassle in the first place, just use the `git difftool $(git merge-base origin/master HEAD)` command every time instead!

B) You may also do the comparison withOUT checking out the branch from the PR as follows:
Note: this has the benefit of allowing you to do the comparison withOUT checking out the branch first! This means you can keep open whatever work you currently had open. The downside, of course, is that you can't `git grep`, `grep`, or otherwise search the code base in the modified state, nor use your IDE or editor to explore the changes. Therefore, I highly recommend just doing option A above instead! 
    git fetch origin/branch_from_github_PR  # update your locally-stored remote-tracking branch to origin/branch_from_github_PR
    git difftool $(git merge-base origin/master origin/branch_from_github_PR)

== To move a chunk of commits to a new branch after a merge as though they were squashed & then cherry-picked instead: == 
See the section titled "How to use a patch file as a much easier replacement for squashing", here: https://stackoverflow.com/questions/7566416/how-to-see-which-commits-in-one-branch-arent-in-the-other/60731900#60731900

=== In short: how to use patch files: ===  
[keywords: git patch files, git patch-files, using git patch files, patching commits, moving commits from branch to branch en-masse]  
(Copy/pasted from my answer here: https://stackoverflow.com/questions/7566416/how-to-see-which-commits-in-one-branch-arent-in-the-other/60731900#60731900, and then edited)

    ## How to use a patch file as a much easier replacement for squashing:

    **A work-around is to simply [obtain a patch file](https://stackoverflow.com/questions/28192623/create-patch-or-diff-file-from-git-repository-and-apply-it-to-another-different/28193089#28193089) containing a "squash-equivalent" of all 30 of my commits, patch it onto a new fork of `master` (a new sub-feature-branch), and work from there, as follows:**

        git checkout feature_branch
        # ensure I have the latest changes from master merged into feature_branch
        git merge master 
        # Obtain a patch file, which is the equivalent of a squash of my 30 commits into 1 commit:
        git diff master..feature_branch > mypatch.patch
        git checkout master
        # Create a new, sub-feature branch
        git checkout -b feature_branch2
        # Patch the 30 commit patch file onto it:
        git apply mypatch.patch

    If your patch won't apply, do some Googling. Ex: ["git patch failed"](https://www.google.com/search?q=git+patch+failed&oq=git+patch+failed&aqs=chrome..69i57.5337j0j7&sourceid=chrome&ie=UTF-8). You might try some of these suggestions to force the patch to apply: https://stackoverflow.com/questions/4770177/git-patch-does-not-apply.

    Now I have my 30-commit patch all applied locally, but unstaged and uncommitted.

    ## Now use `git gui` to add files, chunks, and/or lines and break up your big PR or "diff", as you see fit.

    Alternatively, just commit the whole patch/chunk as one commit and be done if your goal is simply to apply all of these changes to this new branch!

== To compare file changes after a major rebase or rebase + cherry-pick: ==  
0. Back up your branch and do the rebase onto latest master (this is overly-simplified, but makes the general point):
    git branch mybranch_bak     # make a backup copy of mybranch called mybranch_bak *before* doing the rebase, just in case you mess up the rebase!
    git rebase -i master        # rebase mybranch onto latest master
1. Figure out which files mybranch_bak changed:
    MERGE_BASE=$(git merge-base master mybranch_bak) && git diff --name-only $MERGE_BASE..mybranch_bak > file_list.txt
2. Now look at any changes, ***in just these files**, between your rebased branch and your backed-up branch, to see how your rebase you just did affected these files you previously had worked in and changed: 
    git checkout mybranch       # Ensure you are in your branch you just rebased
    git difftool branch_bak $(cat file_list.txt)    # Look at the files of interest to see how the rebase affected them; ensure no errors exist or were introduced in the rebase!
[THIS SINGLE-LINE CMD IS BROKEN! JUST USE THE 2-STEP CMD SEQUENCE ABOVE FOR NOW INTEAD.] OR, do it all in one single command!
    CHANGED_FILES="$(MERGE_BASE=$(git merge-base master mybranch_bak) && git diff --name-only $MERGE_BASE..mybranch_bak)" && git difftool branch_bak "$CHANGED_FILES"

== patch files / patches ==

Source: https://stackoverflow.com/questions/28192623/create-patch-or-diff-file-from-git-repository-and-apply-it-to-another-different/28193089#28193089
git diff tag1..tag2 > mypatch.patch = produce a patch file with the differences from tag1 to tag2
git apply mypatch.patch = apply all the changes detailed in mypatch.patch
git add -A && git commit = add and commit the changes just applied via the patch command above 
SEE ALSO MY ANSWER HERE ABOUT OBTAINING A PATCH FILE WHICH IS THE EQUIVALENT OF A BIG SQUASH AFTER A MERGE!
  https://stackoverflow.com/questions/7566416/how-to-see-which-commits-in-one-branch-arent-in-the-other/60731900#60731900 
BREAKING UP A BIG DIFF! ^^ See the link to my answer just above!

git branch --edit-description = edit a description of your branch stored in your project's local ".git/config" file; see: https://stackoverflow.com/questions/2108405/branch-descriptions-in-git/8858853#8858853 
See also: https://github.com/bahmutov/git-branches
    git branch --edit-description
    git config branch.master.description "description text"  <=======
    git config branch.master.description
And: https://glebbahmutov.com/blog/git-branches-with-descriptions/#disqus_thread

git clean -fd = WARNING WARNING WARNING THIS IS *DESTRUCTIVE*!!! REMOVE ALL UNTRACKED FILES AND DIRECTORIES; see: https://stackoverflow.com/questions/61212/how-to-remove-local-untracked-files-from-the-current-git-working-tree/64966#64966 

== to delete a branch: == 

There are actually **3 different branches to delete!**. Read more here: https://stackoverflow.com/questions/2003505/how-do-i-delete-a-git-branch-locally-and-remotely/23961231#23961231
1. Deleting a **local branch**:
    git branch --delete <branch>
    git branch -d <branch> # Shorter version
    git branch -D <branch> # Force-delete un-merged branches
2. Deleting a **remote branch**:
    git push --delete origin <branch>  # Git version 1.7.0 or newer
    git push -d origin <branch>        # Shorter version (Git 1.7.0 or newer)
    git push origin :<branch>          # Git versions older than 1.7.0
3. Deleting a **remote-tracking branch**:
    git branch --delete --remotes <remote>/<branch>
    git branch -dr <remote>/<branch> # Shorter <===
    -----
    git fetch --prune <remote> # Delete multiple obsolete remote-tracking branches; ie: "Before fetching, remove any remote-tracking references that no longer exist on the remote."--see `man git fetch` then search for "prune"
    git fetch -p <remote>      # Shorter version of the above

== other: == 

git rev-parse HEAD = obtain the git hash for HEAD; see: https://stackoverflow.com/questions/949314/how-to-retrieve-the-hash-for-the-current-commit-in-git/949391#949391
git rev-parse HEAD~4 = obtain the git hash 4 commits prior to HEAD; this is REALLY USEFUL, for instance, when trying to figure out which commit is N commits back when there have been multiple merges and it's confusing which commit was on which fork of those branches when looking at just `git log`. `git lg`, therefore, becomes much more important and useful as well, as it graphically shows these forks, branches, and merges in tree form!

git checkout -- my_file.txt = [WARNING: DESTRUCTIVE OF LOCAL COPY!] check out my_file.txt from HEAD and make it overwrite the current local copy I have! Good for "reverting" local, uncommitted changes on a file or two you're working on and messed up.

git diff --name-only <commit_hash1>..<commit_hash2> | wc -l = see how many files were changed between commit_hash1 and commit_hash2

== Changing commit history author info (name and email address): == 
See: https://help.github.com/en/github/using-git/changing-author-info

In case you made a mistake and had your name and/or email wrong while pushing commits, there's a way to go back and rewrite the history of your entire repo, fixing the author info. 
CAUTION: this rewrites the whole history of your repo, meaning ALL (I believe) commit hashes IN ALL BRANCHES IN THE ENTIRE REPO will be changed when done, which means NO common merge-base will exist with any prior, unmerged branches or commits, and anyone who has forked your repo will no longer be able to merge into it without conflicts until they do a *hard reset* to reset their repo back on top of your changed repo, like this:

- Perform a hard reset of your local `master` branch onto the latest `upstream/master` branch:

    git fetch --all 
    git checkout master
    # reset their local `master` branch onto your latest, rewritten, upstream master branch (as
    # stored locally on their PC as remote-tracking-branch `upstream/master`)
    git reset --hard upstream/master  # WARNING: this is destructive of any local changes or differences

So, here's how to rewrite the history. See GitHub's instructions here: https://help.github.com/en/github/using-git/changing-author-info

1. Open Terminal.
2. Create a fresh, bare clone of your repository:

    git clone --bare https://github.com/user/repo.git
    cd repo.git

3. Copy and paste the script, replacing the following variables based on the information you gathered:
    1. OLD_EMAIL
    2. CORRECT_NAME
    3. CORRECT_EMAIL

        #!/bin/sh

        git filter-branch --env-filter '

        OLD_EMAIL="old_email@gmail.com"
        CORRECT_NAME="Your_Correct_Full_Name"
        CORRECT_EMAIL="correct_email@gmail.com"

        if [ "$GIT_COMMITTER_EMAIL" = "$OLD_EMAIL" ]
        then
        export GIT_COMMITTER_NAME="$CORRECT_NAME"
        export GIT_COMMITTER_EMAIL="$CORRECT_EMAIL"
        fi
        if [ "$GIT_AUTHOR_EMAIL" = "$OLD_EMAIL" ]
        then
        export GIT_AUTHOR_NAME="$CORRECT_NAME"
        export GIT_AUTHOR_EMAIL="$CORRECT_EMAIL"
        fi
        ' --tag-name-filter cat -- --branches --tags

4. Press Enter to run the script.
5. Review the new Git history for errors.
6. Push the corrected history to GitHub:

    git push --force --tags origin 'refs/heads/*'

7. Clean up the temporary clone:

    cd ..
    rm -rf repo.git

8. [GS-added] Now update your local ".git/config" file in this repo, OR your user-level "~/.gitconfig" file in your user home directory, ***to ensure your new name and email are correct SO THAT ALL FUTURE COMMITS YOU MAKE in this repo will have your new, correct name and email as well!***

    # assuming you're in your repo of interest, run this to open the editor and edit this repo's
    # git config file (alternatively, edit your user-level git config file with 
    # `gedit ~/.gitconfig`)
    gedit .git/config  

  Then, ensure the following is somewhere in the file. If it isn't, add it to the bottom!

    [user]
        name = Your_Correct_Full_Name
        email = correct_email@gmail.com


====================================================================================================
= github: = 
====================================================================================================

- This is mostly to describe things like doing searches on GitHub. For `git` commands related to GitHub, see the "= git: =" section above instead.

== GitHub search: == 
1. See my longer answer and "GitHub search quick-reference cheat sheet" here: https://stackoverflow.com/questions/29136057/can-i-search-github-labels-with-logical-operator-or/61618255#61618255
1. See my shorter answer here. This is a summary of what to expect when using the GitHub global search bar versus the GitHub Pull Request search bar: https://webapps.stackexchange.com/questions/57933/how-to-search-with-logic-operators-on-github/142071#142071

The following content is my own content that I wrote, originally copy/pasted from [here](https://stackoverflow.com/questions/29136057/can-i-search-github-labels-with-logical-operator-or/61618255#61618255).

# GitHub search quick-reference cheat sheet:
Reminder: [read here](https://webapps.stackexchange.com/questions/57933/how-to-search-with-logic-operators-on-github/142071#142071) for a quick refresher/summary of what to expect when using the GitHub global search bar versus the GitHub Pull Request search bar.

## DEFAULT GITHUB PULL REQUEST (PR) SEARCHES:
1. All open PRs created by me: 
    1. https://github.com --> click "Pull requests" at the *very top*. 
    1. Direct link: https://github.com/pulls
1. All open PRs assigned to me: 
    1. https://github.com --> "Pull requests" --> "Assigned".
    1. Direct link: https://github.com/pulls/assigned
1. All open PRs which mention me in a comment (via @my-username): 
    1. https://github.com --> "Pull requests" --> "Mentioned".
    1. Direct link: https://github.com/pulls/mentioned
1. All open PRs for which my review is requested:
    1. https://github.com --> "Pull requests" --> "Review requests".
    1. Direct link: https://github.com/pulls/review-requested

## CUSTOM GITHUB PULL REQUEST (PR) SEARCHES:
-----------------------------------------
1. SEE ALL OPEN PRS--BY AUTHOR
Sample Chrome bookmark to create to one of these URLs: "PRS BY AUTHOR--Username 1"
-----------------------------------------
    1. Using the Pull request search bar:
        1. https://github.com --> click "Pull requests" at the *very top*. 
        1. Direct link: https://github.com/pulls
        1. Now use the search bar at the top-center/top-right.
        1. _Note that this search bar is limited to only one author at a time:_

                is:open is:pr archived:false author:username-1
                is:open is:pr archived:false author:username-2 
                is:open is:pr archived:false author:username-3 
                is:open is:pr archived:false author:username-4

        1. Here is a sample URL for the first of the 4 searches just above: https://github.com/pulls?q=is%3Aopen+is%3Apr+archived%3Afalse+author%3Ausername-1
            1. Now create a Google Chrome shortcut named "PRS BY AUTHOR--Username 1", pointing to this URL!

    1. Using the GitHub global search bar (main search bar at top-left of any GitHub page):
        - This search bar allows multiple authors at once, but displays slightly differently than (doesn't look as good as) the Pull request search above:

                is:open is:pr archived:false author:username-1 author:username-2 author:username-3 author:username-4

        - Here is what the URL looks like after performing this search in the GitHub global search bar: https://github.com/search?q=is%3Aopen+is%3Apr+archived%3Afalse+author%3Ausername-1+author%3Ausername-2+author%3Ausername-3+author%3Ausername-4
            - Now create a Google Chrome shortcut named "PRS BY AUTHOR--ALL", pointing to this URL!

-----------------------------------------
2. SEE REVIEW REQUESTS of me from AUTHOR
Sample Chrome bookmark to create to one of these URLs: "REVIEW REQUESTED BY--Username 1"
-----------------------------------------
    1. Using the Pull request search bar:
        - Note that this search bar is limited to only one author at a time: 

                is:open is:pr archived:false review-requested:my-username author:username-1
                is:open is:pr archived:false review-requested:my-username author:username-2
                is:open is:pr archived:false review-requested:my-username author:username-3
                is:open is:pr archived:false review-requested:my-username author:username-4

        - Here is a sample URL for the first search above: https://github.com/pulls?q=is%3Aopen+is%3Apr+archived%3Afalse+review-requested%3Amy-username+author%3Ausername-1
            - Now create a Google Chrome shortcut named "REVIEW REQUESTED BY--Username 1", pointing to this URL!

    1. Using the GitHub global search bar (main search bar at top-left of any GitHub page):
        - This search bar allows multiple authors at once, but displays slightly differently than (doesn't look as good as) the Pull request search above:

                is:open is:pr archived:false review-requested:my-username author:username-1 author:username-2 author:username-3 author:username-4

        - URL produced by the above global search: https://github.com/search?q=is%3Aopen+is%3Apr+archived%3Afalse+review-requested%3Amy-username+author%3Ausername-1+author%3Ausername-2+author%3Ausername-3+author%3Ausername-4
            - Now create a Google Chrome shortcut named "REVIEW REQUESTED BY--ALL", pointing to this URL!


====================================================================================================
= ssh: = 
====================================================================================================
[incl: sshfs, ssh, putty, etc.]

== ssh keys: == 
- including for use with GitHub

Key setup: see: 
1. https://help.github.com/en/enterprise/2.20/user/github/authenticating-to-github/connecting-to-github-with-ssh
1. Generating a key: https://help.github.com/en/enterprise/2.20/user/github/authenticating-to-github/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent

GENERATE SSH KEYS:
ssh-keygen -t rsa -b 4096 -C "your_email@example.com" = generate a 4096-bit RSA key (strong encryption--industry standard today)
OR
ssh-keygen -t rsa -b 4096 -C "your_email@example.com" -f ~/.ssh/id_rsa = same as above, except **explicitly** tell it to save the private key into the output file "~/.ssh/id_rsa"!
ssh-keygen -t ed25519 -C "your_email@example.com" = BEST and FASTEST and NEWEST encryption (better than the RSA one above, but not yet as widely supported; works fine on GitHub though!)

READ SSH KEYS AND CHECK THEIR FINGERPRINTS:
- See: https://stackoverflow.com/questions/9607295/calculate-rsa-key-fingerprint/32130465#32130465
ssh-keygen -lf ~/.ssh/id_rsa = 'l'ist the fingerprint of the 'f'ile ~/.ssh/id_rsa, which is the private key. The default fingerprint type is "sha256" (`-E sha256`)
ssh-keygen -E sha256 -lf ~/.ssh/id_rsa = exact same thing as above, except explicitly setting the fing'E'rprint type to sha256
ssh-keygen -E sha256 -lf ~/.ssh/id_rsa.pub = exact same thing as above, except using the public (.pub) key instead of the private one
ssh-keygen -E md5 -lf ~/.ssh/id_rsa.pub = 'l'ist the fing'E'rprint of this public key 'f'ile using the md5 hash, WHICH IS THE SAME FINGERPRINT HASH THAT GITHUB USES ONLINE IN CASE YOU ARE TRYING TO COMPARE YOUR HASH AGAINST WHAT GITHUB IS SHOWING TO SEE WHICH KEY IS BEING USED ON GITHUB! <===========
- Note that using the *private* key in the above commands has the added benefit of telling you also *what the public key file is named and where it is located*, and *what type the key is!* The key type will be listed in parenthesis at the very end. Ex: '(ED25519)' or '(RSA)'.

COPY PUBLIC SSH KEY TO ANOTHER COMPUTER FOR KEY-BASED/PASSWORD-LESS LOGON:
ssh-copy-id -i ~/.ssh/id_rsa.pub user@hostname_or_ip_addr = copy your public identity file (public SSH key) "~/.ssh/id_rsa.pub" to the computer user@hostname_or_ip_addr into its ~/.ssh/authorized_keys file.
- See: https://askubuntu.com/questions/4830/easiest-way-to-copy-ssh-keys-to-another-machine/4833#4833
cat ~/.ssh/id_rsa.pub | ssh user@hostname_or_ip_addr 'cat >> ~/.ssh/authorized_keys && echo "Key copied"' = alternative, more "manual" way to do the above, manually copying your .pub public key into the server/host's "~/.ssh/authorized_keys" file!
- See: https://askubuntu.com/questions/4830/easiest-way-to-copy-ssh-keys-to-another-machine/6186#6186

== sshfs: ==
sshfs -o reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 username@server_hostname:/path/on/server/to/mount ~/mnt/my_server = do an ssh 'F'ile 'S'ystem mount of a remote PC's disks to your local PC, over ssh. More specifically: mount path "path/on/server/to/mount", on the server "username@server_hostname", to your local disk at location "~/mnt/my_server", doing some fancy keep-alive stuff to keep the connection from going stale and disconnecting you!
- See: [my own ans] https://askubuntu.com/questions/791002/how-to-prevent-sshfs-mount-freeze-after-changing-connection-after-suspend/942820#942820


====================================================================================================
= grep: = 
====================================================================================================

*****See my own answer here, for instance, for `grep` & `git grep` examples: https://stackoverflow.com/questions/60843047/locating-a-function-in-a-git-repository/60843055#60843055

time git grep -E -n "\bmyFuncName\b" = do a *whole word search* (hence the \b surrounding the search string) for "myFuncName", displaying li'n'e 'n'umbers (`-n`) too 

== Exlude a word: == 
Use the `-v`, or `--invert-match` option! See:
1. https://stackoverflow.com/questions/4538253/how-can-i-exclude-one-word-with-grep/4538335#4538335
1. https://stackoverflow.com/questions/10411616/grep-regex-not-containing-string/10411661#10411661
    grep "pattern_to_find" file | grep -v "pattern_to_exclude" = search for "pattern_to_find" while EXCLUDING (in'v'erting the match on) "pattern_to_exclude"  <==== EXCLUDE WORD(S) WHEN GREP-SEARCHING! =====
OR
    grep -v "unwanted_word" file | grep "wanted_word" = same as above, just in the opposite order is all.

Here's some examples. This outputs "redhat" and "yellowtail":
    $ echo "redhat redwood redbox redding yellowtail" | grep -E -o "(redhat|yellowtail)"
    redhat
    yellowtail
So this outputs just "yellowtail", by then excluding anything with "red" in it!:
    $ echo "redhat redwood redbox redding yellowtail" | grep -E -o "(redhat|yellowtail)" | grep -v red
    yellowtail

find -type f | grep -v \.xml | xargs grep --color=always my_regex_search = find only 'f'iles (no directories) which do NOT end in .xml, then search each of those files to see if they contain "my_regex_search" <====== VERY USEFUL! =======

find some/path/ -maxdepth 1 -type d | grep "_messages$" = find only 'd'irectories (`-type d`) in some/path/, only 1 layer deep (`-maxdepth 1`), which have names that end in (`$` indicates a line end) "_messages"


====================================================================================================
= Jinja2: = 
====================================================================================================

- a template-based automatic code/file generator (think string formatter/replacer for an entire text file).

Main Jinja2 References:
1. [Main Jinja2 website](https://jinja.palletsprojects.com/en/2.11.x/)
2. [Entire Jinja2 documentation in PDF form](https://jinja.palletsprojects.com/_/downloads/en/2.11.x/pdf/)
3. [Jinja2 Python API](https://jinja.palletsprojects.com/en/2.11.x/api/)
4. [Jinja2 Template Designer (used for writing template files, which some people like to end in .j2)](https://jinja.palletsprojects.com/en/2.11.x/templates/)


====================================================================================================
= Linux (General): = 
====================================================================================================
[general linux; linux general]

Linux Terminal shortcuts: https://www.howtogeek.com/howto/ubuntu/keyboard-shortcuts-for-bash-command-shell-for-ubuntu-debian-suse-redhat-linux-etc/
Ex:
    Ctrl + A = go to beginning
    Home = same as above
    Ctrl + E = go to end
    End = same as above
    Ctrl + L = clear screen (same as typing `clear` command)

== Linux terminal options: ==
gnome-terminal = Ubuntu's default terminal
tmux = [see "= tmux: = " section in this doc] terminal session manager 
screen = [GNU screen] terminal session manager 
terminator = *****a terminal program to EASILY allow 4 terminals (2x2) or even 16 terminals (4x4) all in one single window! Great for running ROS, for instance, since it requires so many stinking terminals open! 
 - See here, **including my comments under the answer!** 
   https://askubuntu.com/questions/612131/how-to-display-more-than-1-terminal-simultaneously/612139#612139
 - See also: [eRCaGuy_dotfiles/useful_apps/README.md](useful_apps/README.md)

== ==

whoami = print your username (helps verify you are logged in under the correct user)
sudo whoami = print your sudo username; it should say "root" since you ran it as `sudo`! This helps verify you have `sudo` access!--ie: that you are a member of the "sudo" group (run `groups` to check), and in the sudoers file (run `sudo visudo`--you should have an entry for your username at the bottom).
w = "Show who is logged on and what they are doing"; great command to ensure you're the only one remotely logged on to a PC, for instance!

df -h = show 'd'isk 'f'ile usage to see how much hard drive/SSD space you have total, used, and remaining
free -h = look at RAM and swap file/swap partition usage [memory free, ram free, swap free]
du -h = see file space usage of every item (file? and folder) in your current directory; NB: just look at the very last line to see the total usage of your current directory!
du -h | tail -n 1 = same as above, except retain ONLY the *last line* so that you can immediately see the total usage of this directory! Sample output:
        100G .
du -h | tail -n 1 | awk '{print $1}' = same as the line just above, except also retain ONLY the *first column* so that you get rid of the extra dot (.) at the end which indicates "current directory". Sample output:
        100G
    See here for `awk` usage help which enabled me to retain only the 1st column above: https://stackoverflow.com/questions/7315587/bash-shortest-way-to-get-n-th-column-of-output/43284174#43284174

== diff: ==

diff file1.txt file2.txt = compare file1.txt and file2.txt for differences! (similar to `git diff`)
diff -u file1.txt file2.txt = same as above, except showing 'u'nified context output, meaning: show 3 lines (by default) of "unified", or intermingled line-by-line, output to show the context around the differences between the left and right files!
diff --unified file1.txt file2.txt = same as above
diff -c file1.txt file2.txt = similar to the above, except show 3 lines for each file of **'c'opied** 'c'ontext instead of line-by-line unified context
diff --context file1.txt file2.txt = same as above
diff -u=10 file1.txt file2.txt = show 10 lines of 'u'nified context instead of the default 3 lines
diff --color=always file1.txt file2.txt = show color output!
diff -u --color=always file1.txt file2.txt = JUST LIKE `git diff`! SHOW COLOR, WITH UNIFIED LINE-BY-LINE CONTEXT, JUST LIKE git diff! <============== BEST ANSWER! [identical output to `git diff`] ===============
diff -u --color=always left_file.txt right_file.txt = same as above, except accentuating the position of the "left" and "right" files <=============

- Note that `man diff` shows that you can use `-` as one of the two files to read from stdinput for that file instead! It says, "FILES  are  'FILE1  FILE2' or 'DIR1 DIR2' or 'DIR FILE' or 'FILE DIR'.  If --from-file or --to-file is given, there are no restrictions on FILE(s).  If a FILE is '-', read standard input.  Exit status is 0 if inputs are the same, 1 if different, 2 if trouble." So, you can do this!:
---
cat left_file.txt | diff -u --color=always - right_file.txt = pipe content in from stdinput as the **left** file (marked by `-` in the `diff` command)!
cat right_file.txt | diff -u --color=always left_file.txt - = pipe content in from stdinput as the **right** file (marked by `-` in the `diff` command)!

- This allows you to do interesting things, such as show how clang-format changes a file, like this:
clang-format myfile.cpp | diff -u --color=always myfile.cpp - = run clang-format on myfile.cpp, sending its clang-formatted output to stdout; pipe this formatted output to `diff`, however, showing 3 lines of 'u'nified output, with color on, comparing the original myfile.cpp on the left to the stdinput piped in as the file on the right. Therefore, the left is the original file and the right is the formatted file. Now, you can see the output of what changes WOULD be made withOUT actually making those formatting changes! It's a sort of clang-format "preview" to see what **would** be done without actually doing it! See the == clang-format: == section above for further details.

== == 

HASH SUM COMMANDS [hash sums, checksums, cryptography, cryptographic checksums, data integrity checksums]:
sha256sum somefile.txt
sha512sum somefile.txt
md5sum somefile.txt = do an MD5 checksum of somefile.txt; note: according to my online research, MD5 checksums are NOT cryptographically sound, but are still ok for use as general-purpose data integrity checksums.
shasum --algorithm 256 somefile.txt = same as `sha256sum somefile.txt`
shasum -a 256 somefile.txt = same as above = same as `sha256sum somefile.txt`
shasum -a 512 somefile.txt = same as `sha512sum somefile.txt`

strings my_binary_file > temp_strings.txt = extract all ASCII strings from the binary file my_binary_file and store them into the text file temp_strings.txt.

hexdump -C my_file = print all chars of the binary or ASCII file, my_file, in hex+ASCII mode (`-C` means "'C'anonical hex+ASCII display"). Ex:
    $ hexdump -C temp_strings.txt 
    00000000  6f 22 6c 69 6e 6b 22 64  68 74 74 70 73 3a 2f 2f  |o"link"dhttps://|
    00000010  77 77 77 2e 72 65 64 64  69 74 2e 63 6f 6d 2f 72  |www.reddit.com/r|
    00000020  2f 41 73 6b 52 65 64 64  69 74 2f 63 6f 6d 6d 65  |/AskReddit/comme|
    00000030  6e 74 73 2f 65 73 74 32  62 34 2f 77 68 61 74 5f  |nts/est2b4/what_|
    00000040  77 6f 75 6c 64 5f 62 65  5f 74 68 65 5f 77 6f 72  |would_be_the_wor|
    00000050  73 74 5f 74 68 69 6e 67  5f 74 6f 5f 70 75 74 5f  |st_thing_to_put_|
    00000060  69 6e 5f 61 5f 70 69 0a  61 74 61 2f 22 63 6f 72  |in_a_pi.ata/"cor|
    ...

gnome-system-monitor = CPU/RAM/network usage monitor GUI
top = basic CLI competitor to gnome-system-monitor
htop = much better (ncurses-based?) CLI competitor to gnome-system-monitor!

LIST RUNNING PROCESSES AND THEIR PROCESS IDS (PIDs):
(See `man ps` for details)
ps aux = list all running processes on the system (using the BSD syntax) <====== MOST COMMON USAGE =====
ps -A = list all running processes on the system (using the standard syntax)
ps -eLf = get info about *threads*
ps -ejH = print a process tree = very helpful to see **what process called what process(es)**!
ps aux | grep "some_name" = find only processes named "some_name", or at least with "some_name" in their output line displayed by `ps aux`

KILL RUNNING PROCESSES:
(see `man kill` for details)
kill -l = list all kill signal options; ex:
    $ kill -l
     1) SIGHUP      2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP
     6) SIGABRT     7) SIGBUS       8) SIGFPE       9) SIGKILL      10) SIGUSR1
    11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM
    16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP
    21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ
    26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR
    31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3
    38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8
    43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13
    48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12
    53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7
    58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2
kill -L = same as above
kill -9 9999 = send KILL signal (#9 in the list above) to Process ID (PID) 9999  <======= VERY COMMON USAGE ========
kill -KILL 9999 = same as above (KILL is #9 in the list above)
kill -SIGKILL 9999 = exact same as above  <======= VERY COMMON USAGE ========
kill -l KILL = look up the "KILL" signal in the list above to retrieve that it is signal "9"
kill -l 9 = look up the number "9" signal in the list above to retrieve that it is signal "KILL" 
kill 9999 8888 = kill both PIDs 9999 and 8888 (can list any number of pids to kill!); the general format is:
kill pid1 pid2 pid3 ... pidn = send the default signal, SIGTERM (or TERM) to all these processes
kill 123 543 2341 3453 = "send the default signal, SIGTERM, to all those processes" (see `man kill`); note that SIGTERM can also be written as TERM or 15.
kill -TERM 123 543 2341 3453    = same as above
kill -SIGTERM 123 543 2341 3453 = same as above  <======= VERY COMMON USAGE ========
kill -15 123 543 2341 3453      = same as above

[disk usage; disk free space; disk space usage]
- See: https://www.ubuntupit.com/best-disk-analyzer-tools-for-linux-system/
sudo baobab = disk usage analyzer GUI (now called simply "Disk Usage Analyzer" in Ubuntu, and it comes with Ubuntu!) 
baobab = same as above, except it can't analyze root directories
qdirstat = a direct competitor GUI tool to analyze disk usage--comparable to baobab/Disk Usage Analyzer
ncdu [options] <dir> = an ncurses-based tool to analyze disk usage in directory "dir"; CLI-based; works ***really well*** and it is ***really fast***, and it also works over ssh!
free -h = show memory and swap total, used, and free space!
(sudo) swapon --show = show swap partition and swapfile status and sizes 
df -h = show disk usage
du -h my_folder = show folder usage
How to make a Linux swapfile; see my own answer here! 
https://stackoverflow.com/questions/55190272/java-lang-outofmemoryerror-when-running-bazel-build/60572662#60572662

less -RFX myfile.txt = open up myfile.txt in the "less" stream viewer/pager, with the following options, which make it act **identically** to how the output from `git diff` acts! Note: I borrowed my explanations here from the bottom of my own "eRCaGuy_dotfiles/useful_scripts/git-diffn.sh" (`git diffn`) script I wrote herein. 
-R = interpret ANSI color codes
-F = quit immediately if the output takes up less than one screen
-X = do NOT clear the screen when less exits
See also:
  1. https://stackoverflow.com/questions/2183900/how-do-i-prevent-git-diff-from-using-a-pager/14118014#14118014
  2. https://unix.stackexchange.com/questions/38634/is-there-any-way-to-exit-less-without-clearing-the-screen/38638#38638

watch -n INTERVAL_IN_SECONDS COMMAND = run COMMAND and display its output every INTERVAL_IN_SECONDS seconds! See: https://linuxize.com/post/linux-watch-command/; ex:
watch -n 30 'du -h ~/.cache | tail -n 1' = display the disk usage in your ~/.cache dir every 30 sec! Very useful when you are watching a large bazel build cache grow, for instance! Ex:
watch -n 30 'du -h ~/.cache/bazel | tail -n 1' = watch your bazel build cache (in ~/.cache/bazel) grow every 30 seconds--ex: during a large build; it can be useful to watch the directory grow as evidence that the build is progressing properly; note: you may need to use sudo in the command `watch` is running for it to check the size of *all* objects:
watch -n 30 'sudo du -h ~/.cache/bazel | tail -n 1' = same as above, except with the subcommand, `du`, as root, so it can read *all* items, even those in your cache which may be owned by root

== IP & Networking: ==

ifconfig = show the internet & network configuration/connection information for your system and all of its network cards (both wireless (ex: WIFI) and wired (ex: Ethernet ports))

ip help = show the options and `OBJECT`s available for the `ip [OPTIONS] <OBJECT>` commands!
- See also MY ANS HERE! https://unix.stackexchange.com/questions/152331/how-can-i-create-a-virtual-ethernet-interface-on-a-machine-without-a-physical-ad/593142#593142
ip address = show all configured network interfaces and their IP addresses & network interface info; NB: I don't really understand this command yet, but it looks useful, and seems to show a bunch of the same information as `ifconfig`.
ip addres = same as above
ip addre = same as above
ip addr = same as above
ip add = same as above
ip ad = same as above
ip a = same as above
^^ Note the trend! So long as the command can be figured out and determined to be distinct from all other command possibilities, it is accepted! Therefore, you only need as many characters in the OBJECT as are required to make it distinct from all other OBJECT possibilities for this command!

[virtual interfaces, virtual network interfaces, virtual network devices, virtual devices]
Learn how to make **virtual network interfaces** here! 
- Sometimes, you must create a virtual interface to simulate a connected hardware network card with a certain IP address so that software you have which is trying to open up a network socket to that specific device at that specific IP is able to do so, _even if the hardware isn't actually physically present on the PC you are running the software!_ Very useful, for instance, on hardware test platforms or HIL test systems. 
  - [MY OWN ANS!] https://unix.stackexchange.com/questions/152331/how-can-i-create-a-virtual-ethernet-interface-on-a-machine-without-a-physical-ad/593142#593142
  - https://unix.stackexchange.com/questions/152331/how-can-i-create-a-virtual-ethernet-interface-on-a-machine-without-a-physical-ad/152334#152334

ssh -X -o "ServerAliveInterval 60" my_username@my_hostname_or_IP = ssh into hostname or IP address my_hostname_or_IP with username my_username, enabling X-window forwarding, and with the additional 'o'ption set to send a heartbeat signal (server "keep alive" message) every 60 seconds, so your session never disconnects automatically!

hostname = show my hostname; ex: mypcname23-aa
nslookup some_ip_address = use 'n'ame 's'erver lookup to try to find the hostname of a given IP address
nslookup some_hostname = the exact reverse of the above: try to find the IP address from a given hostname 

curl = some web utility for interaction with websites; need to learn how to use
wget https://path.to.some.file.to.download = download a file at this URL; shows a nice progress bar and download stats (speed, total size to download, total size downloaded so far, etc.) the entire time!

== CAN Bus and CAN Networking: ==

TODO: need to add this information in here so I don't forget it.

== `head` and `tail`: == 
- Use `head` to output the first part of files
- Use `tail` to output the last part of files
- This works great for piping `grep` output to one of these too!

echo -e "1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10" | head -n 3 = output just the FIRST 3 lines:
    $ echo -e "1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10" | head -n 3
    1 
    2 
    3 
echo -e "1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10" | tail -n 3 = output just the LAST 3 lines:
    $ echo -e "1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10" | tail -n 3 
    8 
    9 
    10

grep -rni --color=always "some search expression" | head -n 50 = output just the FIRST 50 occurrences I find!
grep -rni --color=always "some search expression" | tail -n 50 = output just the LAST 50 occurrences I find!

== awk: == 
Use `awk` to select only certain columns of textual output--see:
1. https://stackoverflow.com/questions/7315587/bash-shortest-way-to-get-n-th-column-of-output/43284174#43284174
1. and https://stackoverflow.com/questions/7315587/bash-shortest-way-to-get-n-th-column-of-output/7315716#7315716

Ex:
    echo "column1 column2 column3 column4" | awk '{print $1}' = select & keep only the 1st column of the text
    echo "column1 column2 column3 column4" | awk '{print $2}' = select & keep only the 2nd column of the text
    echo "column1 column2 column3 column4" | awk '{print $3}' = select & keep only the 3rd column of the text
    echo "column1 column2 column3 column4" | awk '{print $4}' = select & keep only the 4th column of the text

For a full `awk` program example, see the "eRCaGuy_dotfiles/useful_scripts/git-diffn.sh" program, which is written almost entirely in awk!

== Limit CPU usage: == 
[throttle cpu usage]
Limit CPU usage of a process in Linux: https://linoxide.com/linux-how-to/limit-cpu-usage-processes-linux/; ex:
    cpulimit -p 3185 -l 40 = limit Process ID (PID) 3185 to 40% ***of 1 CPU*** max CPU usage; so, for a multi-core machine (ex: 8 cores), to get a total of 40% of all cores you would need to use 0.4*(100/core * 8 cores) = 0.4*800 = 320, like this:
    cpulimit -p 3185 -l 320 = limit PID 3185 to 320% out of 800% (on an 8-core machine) = 320/800 = 40% overall on an 8-core machine!
OR
    cpulimit -e vmware-vmx -l 40 = limit the process named "vmware-vmx" to 40% ***of 1 CPU*** max CPU usage
    cpulimit -e vmware-vmx -l 320 = limit PID 3185 to 320% out of 800% (on an 8-core machine) = 320/800 = 40% overall on an 8-core machine!
So, to limit to 80% on an 8-core machine, use 0.8*800 = 640, like this:
    cpulimit -p 3185 -l 640
Limit to 62.5% on an 8-core machine:
    cpulimit -p 3185 -l 500

This is very useful to limit your CPU usage being used by Bazel, for instance, when it is building for dozens of minutes, or even hours. Note that the Bazel build server JVM is usually just called "java", and can easily be viewed with `ps`, `top`, `htop`, or the `gnome-system-monitor` GUI (my preferred choice).

    sudo apt update
    sudo apt install cpulimit
    # Start your bazel build in one terminal, then in a separate terminal, run the following.
    # Replace <pid> with the Process ID number for your bazel build server process (usually
    # just called "java" when you look at it with `ps`, `top`, `htop`, or `gnome-system-monitor`).
    cpulimit -p <pid> -l 500 # limit your bazel build to 62.5% max CPU usage on an 8-core machine <=====

Leave the `cpulimit` process running as long as you want this limiting effect in place. You don't need to restart it each time you begin a new bazel build, as the bazel build server continues running in the background even after a build completes.

== Mosh: ==
An ssh-replacement program for better connections over wifi, cellular, and long-distance links. It is free software (GNU GPLv3)!
It can decrease response time by a factor of 30~50 on lossy networks (see Wikipedia article below)! Ex: 16.8 seconds response time --> 0.33 seconds, or 5.9 --> 0.19 sec.

References:
1. https://mosh.org/#getting
2. https://en.wikipedia.org/wiki/Mosh_(software)

== Find files and replace text in files: ==

1)
which <some_executable> = show the path to the executable in your path; ex: 
    $ which locate
    /usr/bin/locate
2)
locate <some_name> = find all files with "some_name" in their path or filename, searching EVERYWHERE, starting at the root dir (/)! Note: to search just in the current dir and below, use `find` instead:
    find | grep <some_name>
3)
find = recursively find and print the relative path to all files and directories in the current directory and below

find -type f = recursively find only files (NOT directories)

find | grep "my_file" = find any file with "my_file" in its name
find -L | grep "my_file" = same as above, but also follow symbolic links when searching

find | grep ".*\.txt$" = find any file which MUST END WITH .txt (the $ searches for an "end of line" character to ensure what's just before it is only at the very end of a string)

find | grep -E ".*(\.ino|\.cpp|\.c|\.h|\.hpp|\.hh)" = find any file with one of these extensions

find -L build/bin | grep -ni some_filename = quickly find a newly-built output file (such as an auto-generated source file created by some Bazel `genrule()`) inside of Bazel's output build dir, "build/bin". Note the `-L` to force `find` to follow symbolic links. This is required since Bazel makes all dirs in "build", such as "bin", simlinks. <======== VERY HELPFUL TO QUICKLY FIND A BAZEL BUILD OUTPUT FILE! ==========

`sed`:
sed -i "s|regex_pattern_to_match|replacement_string|g" my_file.txt = 'g'lobally replace (ie: replace all matching occurrences) of "regex_pattern_to_match" 'i'n place in my_file.txt, replacing the matching pattern with "replacement_string"

PUTTING IT ALL TOGETHER:
References:
1. https://linuxize.com/post/how-to-use-sed-to-find-and-replace-string-in-files/
1. https://unix.stackexchange.com/questions/159367/using-sed-to-find-and-replace/159369#159369 (also see my comment under this answer!)
1. *****https://stackoverflow.com/questions/10445934/change-multiple-files/30717770#30717770
1. *****Really good sed reference! https://www.grymoire.com/Unix/Sed.html

find some/path -type f | grep -E ".*(\.ino|\.cpp)" | xargs sed -i "s|regex_pattern|replacement_string|g" = find all files in some/path which end in .ino or .cpp and pipe them to sed. sed will then find and replace all matches of "regex_pattern" with "replacement_string" in these files. <======= BEST NON-WHOLE-WORD MULTI-FILE SEARCH & REPLACE =====
EXAMPLE:
find src/arduino -type f | grep -E ".*" | xargs sed -i "s|printf|sprintf|g"

To match whole words, use the regex `\b` word boundaries!
- See: https://www.oreilly.com/library/view/regular-expressions-cookbook/9781449327453/ch02s06.html
find some/path -type f | grep -E ".*(\.ino|\.cpp)" | xargs sed -i "s|\bregex_pattern\b|replacement_string|g" = same as above, except with `\b` `\b` to make it a whole word search! <======= BEST WHOLE-WORD MULTI-FILE SEARCH & REPLACE =====
EXAMPLE:
find src/arduino -type f | grep -E ".*" | xargs sed -i "s|\bprintf\b|sprintf|g"

== sed: == 
sed = "'s'tream 'ed'itor for filtering and transforming text" [stream editor]
See also the `sed -i` examples just above!

References:
See also the 4 References for sed just above, underneath "PUTTING IT ALL TOGETHER"!
1. *****[explains how to use regex groups () and \1 \2 \3 etc to reference those groups!] https://unix.stackexchange.com/questions/78625/using-sed-to-find-and-replace-complex-string-preferrably-with-regex/78626#78626
1. How to use sed to find and replace text in files in Linux / Unix shell - https://www.cyberciti.biz/faq/how-to-use-sed-to-find-and-replace-text-in-files-in-linux-unix-shell/

Basic usage:
sed -E 's/regexp_search/replacement_str/g' my_file.txt = in my_file.txt, do a 'g'lobal 's'tring replacement, replacing all matches of regular expression regexp_search with "replacement_str".

== wc: == 
wc = 'w'ord 'c'ount

find | wc -l = count and return the number of 'l'ines returned by find, which corresponds to the number of files and folders in a directory and its sub-directories.

== tr: ==
tr = 'tr'anslate or delete characters
<your_command> | tr -d ',' = remove all commas from the output of `your_command`; see: https://stackoverflow.com/questions/12668020/removing-characters-from-grep-output/12668078#12668078

== Basic Process profiling in Linux: ==

cat /proc/<process_ID>/sched = show some profiling/scheduler stats for this process ID (PID) on Linux, including how many threads it has!
ls /proc/<process_ID>/task/ = list the threads in this process!
ls /proc/*/task = list the threads in all multi-threaded processes!

== == 

qpdf --decrypt in.pdf out.pdf = "decrypt"/unlock (cannot truly decrypt/unlock if it requires a password, but works perfectly for "soft locked" documents which do not!) in.pdf, saving its unlocked/"decrypted" form as out.pdf so that you can now edit it with Foxit Reader or whatever! Nice! Now I can create bookmarks, highlight, underline, take notes, and then save these markups! 
- Once I do this, I like to rename "out.pdf" to "some useful name [`qpdf --decrypt`ed]" so I can remember right in the name itself how I did this!

gpg -c myfile.txt = encrypt myfile.txt with a passphrase (symmetric 'c'ipher); a GUI window will pop up, asking you for a password to encrypt the file; enter a password, then it will ask you again; once you enter the password again it will encrypt the file and create a new file called myfile.txt.gpg. You will need to manually delete the old file. 
gpg myfile.txt.gpg = decrypt myfile.txt.gpg back into myfile.txt; it will ask you for the password which was originally used to encrypt it!
- See here for details and where I learned this! https://www.lifewire.com/encrypt-decrypt-password-protect-files-linux-4582604


====================================================================================================
= Image and video compression and conversion: = 
====================================================================================================
[keywords: compressing videos, compressing images, compressing pictures, image/picture compression, video conversion, image conversion, picture conversion, converting videos, converting images, converting pictures]

== find large files: ==
[this is adjacently related to video conversion, as GitHub doesn't allow files > 100 MB in size (see: https://stackoverflow.com/questions/38768454/repository-size-limits-for-github-com/59479166#59479166), so you may need to find all files > 100 MB, then convert them down to a smaller size using `ffmpeg` as shown below if they are videos!]

find . -type f -size +100M = find all files in the current directory that are larger than 100 MB! See: https://superuser.com/questions/204564/how-can-i-find-files-that-are-bigger-smaller-than-x-bytes/204571#204571

== PDF to images: ==

pdftoppm
See: [MY OWN ANS!] https://stackoverflow.com/questions/43085889/how-to-convert-a-pdf-into-jpg-with-commandline-in-linux/61700520#61700520

== Image resizing: ==
[resize image, resize picture, picture resizing]

convert in.png -resize 600x400 out.jpg = resize to make the dimensions max 600x400, while still retaining proportional dimensions to the original image, while also converting from the (uncompressed I think?) PNG format to the compressed JPEG format. See: https://askubuntu.com/questions/271776/how-to-resize-an-image-through-the-terminal/271797#271797
convert in.png -resize 800x800 out.jpg = same as above, but make the max dimension on either the x or y axis 800 pixels

== Image compression: ==
[picture compression]

See: https://github.com/ElectricRCAircraftGuy/PDF2SearchablePDF
ex:
jpegoptim --size=500k dir_of_imgs/*.jpg = compress the whole dir of images!

== Video compression: ==

sudo apt install ffmpeg = install ffmpeg (required below)
sudo apt install vlc = install the VLC media player GUI application to play the converted videos below

SUMMARY:
- libx265 (H.265) format crf values may be as high as 24 to 30 (higher values are lower quality).
- Note that HIGHER crf settings below yield SMALLER files because they are *lower* quality!

    # For "large" output files (usu. < 100 MB):
    time ffmpeg -i input.mp4 -vcodec libx265 -crf 24 output.mp4   <====== BEST FOR SLIGHTLY HIGHER QUALITY =======

    # For "small" output files (usu. < 50 MB):
    time ffmpeg -i input.mp4 -vcodec libx265 -crf 28 output.mp4   <=========== BEST FOR SMALLER FILES ============

DETAILS:
See: https://unix.stackexchange.com/questions/28803/how-can-i-reduce-a-videos-size-with-ffmpeg/38380#38380
ex:
time ffmpeg -i input.mp4 -vcodec libx265 -crf 28 output.mp4 = [PRODUCE "SMALL" VIDEO OUTPUT FILES!] convert input.mp4 to output.mp4 using the modern H.265 video format, which has EXCELLENT size vs quality! Reasonable compression (-crf) values for this libx265 (H.265) format may be as high as 24 to 30 (28 is good to make very small videos, but to get a touch more quality, use 24 instead!), with LOWER CRF values yielding HIGHER bitrates, and hence HIGHER quality videos! <============= WORKS REALLY WELL! ==============
- Using the above command: <============= MY FAVORITE TO GET VERY SMALL SIZES IN VIDEO OUTPUTS! ==================
    - a 110 MB 15 min video might take 25 minutes to convert (1/0.6 time factor to convert), and drop to as little as 35 MB!, and
    - a 125 MB 1min40sec video might take 5~6 minutes to convert (1/0.3 time factor to convert) and drop to as little as 5 MB!
    - a 503 MB 6 min .mov video might take 60 minutes to convert (on a slow computer [2-core/4-thread, Pentium i3 or similar], ~1/0.1, or 10x time factor to convert) and take as little as 32 MB when done! 32MB/503MB = ~6% of original size, or about 100% - 6% = 94% compression ratio!
        - Note: on a faster, modern computer [4-core/8-thread or 6-core/12-thread, Pentium i7 or similar] the whole conversion process might take only 4 to 10 minutes instead of 60 minutes! So, buy a nice computer.
time ffmpeg -i input.mp4 -vcodec libx265 -crf 24 output.mp4 = [PRODUCE "LARGE" VIDEO OUTPUT FILES!] exact same as above except with CRF of 24 instead of 28 in order to get a touch **higher quality** out of the video! <============ MY FAVORITE FOR SLIGHTLY HIGHER QUALITY! ===========


====================================================================================================
= flowcharts and drawing tools, graphics, emojis, unicode chars & icons, etc.: = 
====================================================================================================

Every piece of software is benefited by flowcharts, diagrams, and drawings to show how it works and how the data flows. Here are a few popular options:

1. *****LucidChart: https://www.lucidchart.com
    1. It is paid/professional (probably the industry standard), but has a free light version--sign up with just an email address
1. ****Google Slides/Docs/Drawings: docs.google.com
    1. A bit simplistic, but works
1. ***LibreOffice Draw
1. *****+AsciiFlow: http://asciiflow.com/; and on GitHub: https://github.com/lewish/asciiflow2
    1. Probably my favorite! 
    1. Super simple, ASCII-text-based drawing tool for easily pasting ASCII flow chart drawings into text files such as readmes or as comments/documentation inside actual code files.
    1. Looks great inside GitHub markdown readmes when pasted as though it was a code snippet!
    1. For inserting symbols, emojis, specialty icons, etc, as unicode chars, just copy and paste from one of the nice lists shown below: 
1. *****For other ASCII-based drawing options, see here! https://unix.stackexchange.com/questions/126630/creating-diagrams-in-ascii
1. Dot (a scripted flow-chart drawing tool) & GraphViz

== Unicode icons/chars/emojis: == 

1. Graphics available on GitHub, apparently: https://gist.github.com/rxaviers/7360908
    Ex: `:goat:`, `:rooster:`, `:+1:`, etc.
2. A ton of unicode chars, including with color graphics: https://gist.github.com/endolith/157796
    Ex: 
    🎃 Jack-O-Lantern
    🎄 Christmas Tree
    🎅 Father Christmas
    🎆 Fireworks
    🎇 Firework Sparkler
    🎈 Balloon
    🎉 Party Popper
    etc.
3. Just some very basic ASCII graphics and symbols: https://gist.github.com/spudbean/1558257
    Ex:
    ◔̯◔ [sad]
    ⊙︿⊙ [sad]
    ◕︵◕ [sad]
    ●︵• [sad]
    ◉︵◉ [really sad]
    ಡ_ಡ [misty eyes]
    ಥ_ಥ [crying]
    ಢ_ಢ [crying]
    ಢ_ಥ [heavily distraught]
    ⊙﹏⊙ [embarrassed]
    ( ﾟoﾟ) [surprised]
    ⋋_⋌ [frustrated]
    〴⋋_⋌〵[angry]


====================================================================================================
= ros: = 
====================================================================================================
ROS = Robot Operating System  
https://www.ros.org/  
For more of my information on ROS, see my ROS folder here: [eRCaGuy_dotfiles/ros](ros).  

References:
1. https://www.ros.org/
    1. *****+http://wiki.ros.org/
1. https://github.com/ros
    1. https://github.com/ros/ros
1. https://en.wikipedia.org/wiki/Robot_Operating_System
1. *****+[VERY USEFUL!]rosbag command line: http://wiki.ros.org/rosbag/Commandline
1. rosbag/Tutorials/Recording and playing back data - http://wiki.ros.org/rosbag/Tutorials/Recording%20and%20playing%20back%20data
1. rosbag intro video: https://youtu.be/pwlbArh_neU
1. http://wiki.ros.org/rxbag [WX Widgets-based ROS GUI tool--deprecated, replaced by rqt_bag]
1. http://wiki.ros.org/rqt
    1. http://wiki.ros.org/rqt_bag [QT-based ROS GUI tool--replaces rxbag]
1. *****++[CODE SAMPLES & STUFF!] http://wiki.ros.org/rosbag/Cookbook
1. http://wiki.ros.org/rospy
        sudo apt install python-rospy
   See: https://zoomadmin.com/HowToInstall/UbuntuPackage/python-rospy
1. pyrosbag; see:
    1. https://pyrosbag.readthedocs.io/en/latest/installation.html
    1. https://pyrosbag.readthedocs.io/en/latest/usage.html
            pip3 install pyrosbag
                import pyrosbag # in python code
1. *****rostopic: http://wiki.ros.org/rostopic
1. *****++ EXCELLENT CHEAT SHEET: 
    1. Google search for "ros cheat sheet" - https://www.google.com/search?q=ros+cheat+sheet&oq=ros+chea&aqs=chrome.0.69i59j69i57j69i60l3.1626j0j4&sourceid=chrome&ie=UTF-8
    1. EXCELLENT CHEAT SHEET! - https://w3.cs.jmu.edu/spragunr/CS354_S19/handouts/ROSCheatsheet.pdf 

== roscore ==
- See: 
    - http://wiki.ros.org/rosbag/Tutorials/Recording%20and%20playing%20back%20data#Recording_data_.28creating_a_bag_file.29
    - http://wiki.ros.org/roscore
roscore -h = help menu
roscore = start up a "ROS core", which includes a ROS master node; this program is REQUIRED to be running for any ROS nodes to be up and running, for ROS params to be accessed, and for ROS topics to be published or subscribed to. `roslaunch` apparently launches a roscore process as part of its startup.

== roslaunch ==
- http://wiki.ros.org/roslaunch
- a higher-level command to roscore; starts up a roscore process as part of its startup; see: http://wiki.ros.org/roslaunch#roscore
roslaunch -h = help menu
[I'm not really sure how to use this program yet]

== rosbag info ==
- http://wiki.ros.org/rosbag/Commandline#info
- show info about the bag file
- does NOT require a master node, via `roscore`, to be running first.
rosbag info -h = help menu
rosbag info myfile.bag = display a summary of the contents of the bag file(s) myfile.bag, including showing a list of all message types in the bag file, and a list of all topics published to, with their message types, and the number of times each topic was published to! This is very useful if you need to just see if a certain topic exists (was published to *at all*) in a given bag file! Ex:
rosbag info myfile.bag | grep -E "(my_topic_2|my_topic_1)" = show if my_topic_1 and my_topic_2 exist at all (were published to at all) in this bag file, and if so, how many times and what are their message types in these topics

== rosbag play ==
- http://wiki.ros.org/rosbag/Commandline#play
- plays back a recorded bag file in the same time span it was originally recorded
- DOES require a master node, via `roscore`, to be running first.
NB: *NOT* all of the CLI options are described on the website! See `rosbag play -h` for additional options! Ex:
  --try-future-version  still try to open a bag file, even if the version
                        number is not known to the player
  --topics              topics to play back
  --pause-topics        topics to pause on during playback
  --bags=BAGS           bags files to play back from
rosbag play -h = help menu
rosbag play myfile.bag = play back the contents of bag file(s) myfile.bag, in a time-synchronized fashion (and at the same rates/time intervals as they were originally recorded); this is very useful for spoofing a system in order to replay live data, test systems and algorithms, test a robot's response to replayed inputs, etc. See: http://wiki.ros.org/rosbag/Commandline#play
rosbag play -i myfile.bag = play back the whole file "'i'mmediately", or as fast as possible, rather than in a time-synchronized fashion; watch out! "For large files this will often lead to exceeding your incoming buffers."
rosbag play --loop myfile.bag = continually play myfile.bag on a loop; ie: when done playing back the file, start back over from the beginning again, repeatedly
rosbag play myfile.bag --topics topic1 topic2 = play back only topic1 and topic2 from myfile.bag! See `rosbag play -h` for where I found this. Also see this question here for where I first saw it: https://answers.ros.org/question/228676/exclude-some-topics-from-rosbag-play/
rosbag play myfile.bag --topics topic1 --topics topic2 = same as above, but using the `--topics` flag repeatedly; just use the shorter syntax above instead!

== rosbag filter ==
- http://wiki.ros.org/rosbag/Commandline#filter
- scans through a bag file and produces a new bag file containing only the content you are filtering on with your python filter command.
- does NOT require a master node, via `roscore`, to be running first.
rosbag filter -h = help menu
rosbag filter input_file.bag new.bag "'topic1' in topic or 'topic2' in topic" = read in the input_file.bag bag file, and store any topics with the string "topic1" or "topic2" anywhere in their name into a new output bag file called new.bag. Note: this works, but it can potentially take a long time! On a 1 GB bag file, it might take up to 5 to 10 minutes or more, and some bag files could be as large as dozens of GB, which could take up to a couple hours just to filter out some messages on a few topics. There's got to be a faster way, especially if you just want to view the first few messages on a given topic, for instance...
rosbag filter --print="'%s @ %d.%d: %s' % (topic, t.secs, t.nsecs, m.data)" input_file.bag new.bag "'topic1' in topic or 'topic2' in topic" = print message.data (`m.data`) for any messages with topic1 or topic2 in theit topic names, while creating a new output bag file; I can't seem to get this to work quite right, but it's something like this...

== rostopic ==
- http://wiki.ros.org/rostopic
rostopic -h = help menu

== rostopic echo ==
- http://wiki.ros.org/rostopic#rostopic_echo
- DOES require a master node, via `roscore`, to be running first.
rostopic echo -h = help menu
rostopic echo /my/ros/topic = echo (print to the terminal) any messages on this topic which are currently being published! (by a node, or played back by `rosbag play`)

== rostopic list ==
- http://wiki.ros.org/rostopic#rostopic_list
- DOES require a master node, via `roscore`, to be running first.
rostopic list -h = help menu
rostopic list -v = list full details ('v'erbose mode) about each topic currently being played/published! See: http://wiki.ros.org/rosbag/Tutorials/Recording%20and%20playing%20back%20data#Recording_all_published_topics and the `rostopic list -h` help menu.

== HOW TO READ MESSAGES FROM DESIRED TOPICS IN A BAG FILE ==
- Let's say I want to see all messages on topic1, topic2, and topic3 in a huge (could be many GB) bag file; how do I read them? 

OPTION 1: 
Play them live as quickly as possible, and look at the output in various terminals.
Pros: runs QUICKLY (~10 sec, for instance, once you get all the terminals set up).
Cons: requires a bunch of separate terminals and processes and a `roscore` running, and is a bit of a pain to set up.

    # 0. In any terminal, ensure you know the topic names *exactly*.
    # A) manually inspect all published topics and how many messages were published to each topic
    time rosbag info mybag.bag  
    # OR, B) grep for some keywords you're looking for which you know make up the topic names
    time rosbag info mybag.bag | grep -E "(topic1|topic2|topic3)"

    # 1. In terminal 1, start up a ros core, which runs the required ROS master node
    roscore

    # 2. In terminal 2, subscribe to /topic1, echoing (printing) everything published on this topic,
    # while also teeing it to a file for later review, all in yaml format
    rostopic echo /topic1 | tee topic1.yaml

    # 3. In terminal 3, subscribe to /topic2...
    rostopic echo /topic2 | tee topic2.yaml

    # 4. In terminal 4, subscribe to /topic3...
    rostopic echo /topic3 | tee topic3.yaml

    # 5. In terminal 5, play back the bag file now as quickly as possible, publishing ONLY the
    # topics of interest. Note: on a 10GB~20GB or so sized bag file, this might take 10 or so
    # seconds on a high-speed SSD, so it is really quite fast! The underlying functionality must be
    # implemented in C++, as I think the Python implementation would take more like 1~2 minutes at
    # least.
    # Play back (publish) just these topics as quickly as possible!
    time rosbag play --immediate mybag.bag --topics /topic1 /topic2 /topic3

OPTION 2 [my preferred approach!]:
Run a short Python program to output just what you want. 
See here for starters: http://wiki.ros.org/rosbag/Cookbook
Main `rosbag` API info pg. (C++ and Python): http://wiki.ros.org/rosbag/Code%20API
Python2 `rosbag` Code API documentation: https://docs.ros.org/api/rosbag/html/python/
- `read_messages()` API documentation: https://docs.ros.org/api/rosbag/html/python/rosbag.bag.Bag-class.html#read_messages
Use this short Python script: "eRCaGuy_dotfiles/useful_scripts/ros_readbagfile.py"
Pros: really easy to use; requires only 1 terminal, and NO `roscore` running.
Cons: this Python implementation runs ~13x slower than the one above, so it might take up to 1 to 2+ minutes to process an entire bag file.
TODO: convert the below Python script to a C++ program using the [C++ rosbag API](http://wiki.ros.org/rosbag/Code%20API#cpp_api).

    # 0. Do step 0 from above (OPTION 1) to ensure you know the topic names *exactly*.
    time rosbag info mybag.bag  
    # OR
    time rosbag info mybag.bag | grep -E "(topic1|topic2|topic3)"

    # 1. Run this script to print all messages on the specified topics from this bag file.
    # This script can be found in the "useful_scripts" folder herein. 
    python2 ros_readbagfile.py <mybagfile.bag> [topic1] [topic2] [topic3] [...]

== C++ Debugging prints in ROS: ==
[ROS debug prints, ROS logger, ROS printing, ROS console]

References (in this order):
1. https://answers.ros.org/question/108646/print-out-the-contents-of-a-string-using-ros_info/
2. http://wiki.ros.org/Verbosity%20Levels
3. http://wiki.ros.org/roscpp/Overview/Logging
4. http://wiki.ros.org/rosconsole
5. https://github.com/ros/rosconsole/tree/noetic-devel/include/ros
    1. https://github.com/ros/rosconsole/blob/noetic-devel/include/ros/console.h
    2. https://github.com/ros/rosconsole/blob/noetic-devel/include/rosconsole/macros_generated.h
6. ROS `std_msgs::`
    1. https://github.com/ros/std_msgs/tree/kinetic-devel/msg
    2. https://github.com/ros/std_msgs/tree/kinetic-devel/include/std_msgs

C++ example debug/info prints in ROS:

    // Note: this header file automatically includes `#include "rosconsole/macros_generated.h"` at 
    // the end
    #include <ros/console.h> 

    #include <std_msgs/String.h>
    #include <std_msgs/Header.h>

    std_msgs::String str;
    std_msgs::Header header;
    std_msgs::Header msg1;
    std_msgs::String msg2;

    // Use like C printf() with standard C types:
    ROS_INFO("my_unsigned_int = %u", my_unsigned_int);
    // Use like C++ cout with ROS messages and streams:
    ROS_INFO_STREAM("header = \n" << header);
    ROS_INFO_STREAM("msg1 = \n" << msg1);
    ROS_INFO_STREAM("msg2 = \n" << msg2);
    // ...etc.

    /*
    See: 
    1. http://wiki.ros.org/Verbosity%20Levels
    2. http://wiki.ros.org/roscpp/Overview/Logging
    3. See also the table under the "Output" section here: 
       http://wiki.ros.org/roscpp/Overview/Logging#Output

    The 5 options include:
    
    ROS_DEBUG()
    ROS_INFO() // normally use this one!
    ROS_WARN()
    ROS_ERROR()
    ROS_FATAL()

    ROS_DEBUG_STREAM()
    ROS_INFO_STREAM() // normally use this one!
    ROS_WARN_STREAM()
    ROS_ERROR_STREAM()
    ROS_FATAL_STREAM()

    DEBUG and INFO print to stdout, whereas WARN, ERRO, and FATAL all print to stderr! See the
    table under the "Output" section here: http://wiki.ros.org/roscpp/Overview/Logging#Output

    */

== == 


====================================================================================================
= Scratch Work/Work in Progress (WIP): = 
====================================================================================================

WORK IN PROGRESS (WIP)
- this is a scratch work place for me to take notes as I discover them.

Trying to create a version of `git diff` which includes line numbers!
Getting there, but numbers + and - lines, thereby making the numbers waaay too long!

    git diff -U100000 --color=always --no-prefix HEAD~ | grep --color=never -m 1 -A 100000 @@ | tail -n +2 | grep --color=never -n .

    git diff -U100000 --color=always --no-prefix HEAD~ | grep --color=never -m 1 -A 100000 @@ | tail -n +2

    git diff -U100000 --color=always --no-prefix HEAD~ | grep -E "@@.{0,20}@@"

GOT ONE! The left-hand (-) side:

WORKS:
    git diff -U100000 --color=always --no-prefix HEAD~..HEAD | grep --color=never -m 1 -A 100000 @@ | tail -n +2 | grep --color=never -v -E $'^\e\[32m\+' | grep --color=never -n .

And now the right-hand (+) side:

WORKS:
    git diff -U100000 --color=always --no-prefix HEAD~..HEAD | grep --color=never -m 1 -A 100000 @@ | tail -n +2 | grep --color=never -v -E $'^\e\[31m-' | grep --color=never -n .

NEXT:
Now, store them into two separate variables, recombine them into one variable, sort them, and delete duplicate lines (lines which are *exactly* identical!) Then display the output. Make it a git alias. Done.

Update: use this as a starting point instead!
  1. https://stackoverflow.com/questions/24455377/git-diff-with-line-numbers-git-log-with-line-numbers/33249416#33249416
  1. See also my question here: https://stackoverflow.com/questions/61932427/git-diff-with-line-numbers-and-proper-code-alignment-indentation




